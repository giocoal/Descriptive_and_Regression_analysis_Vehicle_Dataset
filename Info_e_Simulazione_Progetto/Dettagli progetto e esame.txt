# ESAME SCRITTO(28 pt al più)
	- Risposta multipla e esercizi
	- Le dimostrazioni NON sono temi d'esame
* Ci sarà un preappello:
	Si circa a metà dicembre (nella settimana tra il 13 al 17 dicembre)
# Progetto:
	- Analisi di un dataset a SCELTA (o tra quelli forniti durante il corso)
	- Solo consegnare (non va esposto)
	- Consegnare almeno 10 giorni prima dell'appello via email 
	- Va consengnato il MARKDOWN del progetto
	- vale per tutti gli appelli dell'anno accademico
	- Punteggio massimo 6

*Q&A
1. Possiamo già iniziare adesso?
	- La prima fase è l'analisi esplorativa descrittiva dei dati, quindi possiamo iniziare a farla
	- E man mano che andiamo avanti nel corso possiamo aggiungere dettagli
	
2. Quando va consegnato:
	- almeno 10 giorni prima rispetto a qundo vogliamo fare l'esame
	
3. CHe tipo di dataset:
	- Dataset semplici (da internet o tra quelli proposti)
	- Meglio se non ci siano o siano pochi i valori mancanti
	
4. Come produrlo?
	- COnsiglia di usare R markdown, creiamo la pagina HTML e mandiamo quella
	- Vanno bene anche alternative (quindi anche altri notebook di altra natura)
	
5. Ci sarà un preappello?
	- Si a metà dicembre quindi ha senso iniziare ora
	
6. Quante pagine?
	- Non troppo lungo, non deve essere 50 pagine, deve essere tipo articolo scientifico
7. Che struttura deve avere ?
	- Simile a articolo scientifico: titolo, abstract (dove enuncio gli obiettivi ..) etc
8. Devi studiare con i grafici (box plot e dispersione) tutte le variabili del mio dataset ?
	- Le variabili che vanno introdotte non sono tutte, ma quella variabili significative alle tecniche 
	  utilizzate.
    - Questo significa che quelle che non studiamo, le introdurremo e ne giustificheremo il fatto che non le abbiamo incluse
    - Ma non vanno inseriti i grafici per ogni singola variabile, solo per quelle che poi studio effettivamente
9. Come capisco se un dataset va bene ? Che potrei fare con il dataset?
	- Es. 'winequality-red' di uci repository
	1. Individuo variabile target (in questo caso quality) e le covariate (acidity, citric acid etc)
	2. Osservo le variabili: le covariate sono quantitative (vanno bene) la target è qualitativa (non va molto bene per il modello di regressione)
		- Il modello di regressione lineare dovrebbe in questo caso CLASSIFICARE e non predirre (ci servirebbe più che altro un *modello di regressione logistica*
			- Usare quindi un modello di regressione su questa variabile, per quanto possibile matematicamente (trattandola come factor), sarebbe un ERRORE, NON FARLO !
			- E' un problema di classificazione, non ci interessa per quello che abbiamo studiato noi
		- Potrei limitarmi a fare un'analisi descrittiva e poi osservare se esiste qualche correlazione qualitativa tra le distribuzioni delle covariate e la variabile target 
			(senza fare quindi la regressione)
		- Oppure potrei scegliere una nuova variabile target tra le covariate (sarebbe più complesso)
			- Potrei anche usare la variabile target qualità come variabile dummy nel modello di predizione di una delle covariate (che diventa la nuova target, es. alcool)
10. Posso usare funzioni e pacchetti (tipo tidyverse) ?
	- Si, anzi, se li usiamo è considerato un approfondimento (quindi penso lo consideri per voti in più)
11. Dopo avere scelto un dataset, mandare una **mail** al professore per chiedere se va bene (lui ha detto che possiamo farlo, anzi ci ha invitato a farlo)
12. Dove trovo una traccia ?
	- Una traccia è la simulazione che abbiamo fatto il 4/11 
	- Una traccia è presente nel file R_16
13. Come tratto i valori mancanti?
	- Se non sono tanti elimino la riga
	- Se sono molto elevati utilizzo la media
14  Come tratto i valori estremi ?
	- Se sono pochi elimino la riga
	- Se sono tanti ?
	
*Altre nozioni utili*:
1. Usa la norma 80/20 sul dataset
	- 80% dei dati per ottenere il modello, 20% per testarlo
	- 80% è il TRAINING SET
	- 20% è il TEST SET (utilizzato per testare la bontà della previsione del mio modello)
	- Importante che la scelta delle righe sia randomica (e non basata sull'ordine delle righe), per non portarsi dietro problemi strutturali del dataset
		- righe_training_set <- `sample(1:nrow, nrow*0.8, replace = False)` 
			training_set <- datset[righe_training_set, ]
			test_set <- dataset[- righe_training_set, ]
2. Guarda il file R_15 per tutta la parte di regressione lineare multipla:
	- SOno 40 pagine, mostra tutti i test e i grafici che si fanno sulla regressione lineare multipla, sugli esempi della cartella 'lab regressione lineare.zip'
	- Gli argomenti sono: 1) Regressione 2) Analisi dei residui 3) Valori anomali
3. Dove prendere datasets:
	- **UCI repository**: https://archive.ics.uci.edu/ml/index.php
		- In alto a dx premi 'View ALL Data Sets' -> A sx c'è la sezione 'Default Task' (indica la task statistica per lo specifico dataset)
			-> Premi 'Regression' -> Si visualizzano i dataset utili per fare analisi di regressione
		- Sono tutti dataset modello molto noti ed utilizzati (Aprendo la pagina del ds, in basso c'è la sezione 'Relevant Papers e Citation Request') 
			- Possiamo prendere spunto da questi articoli e usarli per controllare che i risultati ottenuti siano sensati
		- Nella pagina del dataset sono presenti tutte le informazioni riguardo gli attributi
	- **kaggle.com/datasets**
		- Ache qui, sotto la barra ricerca ho la possibilità di scegliere la TASK
4. Cose da fare: (Guarda il 5.2 a pagina 30 di R_5, è un'analisi molto completa)
	- Scelta dataset 
	- Dataset: 
		- Importazione, osservazione del dataset
		- Individuazione variabile target e covariate
	# Analisi DESCRITTIVA e Cleaning: 
		- Se oltre alla Inferenza faccio anche Predizione questa parte va fatta sul Trainin Set (a parte il cleaning) !
		- Se faccio solo inferenza uso il 100% ma poi non potrò fare conclusioni sulla qualità del modello in previsione !
		1) Missing Values (guarda script)
		2) Outliers (guarda script)
		3) Analisi di Distribuzione
			1) Numerical Analysis: Statistical Indicators (mean, st. std, 1 quart, ...)
			- lo faccio con summary()
			2) Visual Analysis: Graph Rappresention (hist, boxplot, scatter plot, etc)
				- Valutare normalità (curtosi etc)
				- Valutare normalità di trasformate
			- Distribuzione di ogni singola variabile
			- Simmetria delle variabili
			- Eventuali altre caratteristiche
	# Inference & Predisction
	- Fase ANALISI ESPLORATIVA PRELIMINARE prima delle costruzione del modello: (da qui in poi basati sugli esempi di R_15)
		- Grafici di dispersione PAIRWISE con pairs()
		- Costruzione della matrice di correlazione 
			- Trovare eventuali problemi di collinearità
			- Trovare la variabile più correlata a y
	- Inizio costruzione del modello, parto con il modello lineare tra y e la covariata più correlata:
		- lm()
		- Valuto la qualità dei parametri e l'R^2 da summary()
		- Analisi dei residui (residui vs fitted, qq-plot): mi permette di capire se davvero il mio modello si adatta ai miei dati
	- Passo al modello lineare multiplo: Aggiungo covariate o covariate quadratiche
		- Lo studio esattamente come quello lineare
	- COnfronto i due modelli costruiti e valuto se c'è stato un miglioramento
		- ANOVA
		- Confronto i valori di RSS tra i due modelli
	- Una volta ottenuto il modello con il migliore R^2: Posso anche fare la procedura backward:
		- Valuto la significatività dei vari parametri con summary
		- Elimino una alla volta le covariate non significative:
			- Elimino la meno significativa
			- Rivaluto la significatività
			- Se altre sono diventate non significative elimino
			- COsì via fin quando sono tutte significative
	- Una volta effettuata l'analisi backward, posso studiare il modello con l'analisi dei residui: (p27 R_5)
		- Non fare i grafici dei residui per tutti i modelli ma solo per quello finale ottenuto
		- Dovremmo sennò fare troppi grafici
		- Uso quindi i residui come ultima analisi per valutare se sia o meno buona
5. Fasi descritte nel file R_16:
	
	
	3.2 Predizioni (usando il comando predict) e poi calcolare la qualità del modello tramite il mean square error

###

########  Importo il dataset ########
## Uso readr (read_csv) che è più ottimizzato
install.packages('readr')
library(readr)
housing <- read_csv('housing.csv', col_names = TRUE, )
View(housing)

######## Statistica Descrittiva ########
######################################## 

###### Osservo il dataset (median_house_value TARGET) ########
class(housing)
dim(housing)
str(housing)
# Il summary oltreutto mi dice, per ogni colonna, se e quanti
# NA sono presenti, capisco quindi quale li ha
summary(housing) # total_bedrooms ha 207 NA
# Ocean Proximity è scritto come chr, lo trasformo in factor
housing$ocean_proximity <- as.factor(housing$ocean_proximity)
str(housing)

############## 1C Missing value ################
# 1) se sono pochi li elimino
# 2) se sono tanti li assegno alla media


### Li cerco
## is.na mi ha una lista di true/false
# NON applicarlo all'intero df!
## sum() mi da il numero di NA (che so gia da summary)
sum(is.na(housing$total_bedrooms))
## which mi da l'indice delle righe
which(is.na(housing$total_bedrooms)) 
### Assegno a nuovo dataset
housing_nona <- housing[-which(is.na(housing$total_bedrooms)), ]

############## 2C Outliers ##############
## Uso library(car) per i boxplot
install.packages('car')
library(car)
## summary() per vedere minimo e massimo
summary(housing_nona) # non ho particolari conoscenze derivate
## Osservo gli istogrammi # non noto particolari
## Osservo i boxplot 
# Hanno tutti outliers tranne prime 3 colonne
for (i in names(housing_nona)) {
  if (i == 'ocean_proximity') {
    break
  }
  else {
    Boxplot(housing_nona[,i], 
            main = i,
            id = list(n=1))
  }
}
# Le righe da eliminare sono troppe, non va bene
## Cosa posso fare per capire meglio questi outliers ?
# 1) Provo ad ottenere la trasformata delle mie variabili
# vedo se cambia qualcosa (dovrebbero diventare più simmetrici
# gli outliers rispetto alla media)
for (i in names(housing_nona)) {
  if (i == 'ocean_proximity') {
    break
  }
  else {
    Boxplot(log(housing_nona[,i], 
                main = i)
    hist(log(housing_nona[,i], 
                main = i))
  }
}
# 2) Essendo comunque molti gli outliers posso pensare a nuovi
# criteri per capire quali righe eliminare
# 2.1) Provo ad aumentare la maglia, anzi che Q[1] - 1.5*iqr
#      provo a fare 3* o 4* o 5*
# 2.2) Controllo quali righe (unità statistiche) hanno quasi
#      tutte le righe outliers
# 3) con eliminated <- subset()
# eliminano e tengo da parte queste righe
# 3.1) Le tengo da parte perchè poi alla fine posso valutare
# se questi sono contemplati comunque nel mio modello di regressione

############### 1C Distribution Analysis #################
# 1) Numerical Analysis: Statistical Indicators (mean, st. std, 1 quart, ...)
# lo faccio con summary()
# 2) Visual Analysis: Graph Rappresention (hist, boxplot, scatter plot, etc)
# 3) Valutare normalità (curtosi etc)
# 4) Valutare normalità di trasformate
  # 4.1) Se ad es il logaritmo di una variabile è normale posso usare la 
      #  trasformata per la regressione

############### 1D Correlation Analysis ############### 
# 1) Matrice di correlazione
res <- cor(housing_nona[, -c(10)])
round(res, 2)
# 2) Scatter plot a coppie
pairs(housing_nona[, -c(10)])
# Vedo se ho covariate con dipendenza tra loro (in questo caso ne ho due)
# Quando valuto la correlazione ne scelgo solo una delle due, QUELLA CHE HA 
# MASSIMA correlazione con la variabile target (ha un potere esplicativo maggiore)
# 3) Elimino dal dataset quella meno correlata 
# 4) Ripeto l'operazione se ci sono altre variabili
# 5) Controllo nuovamente il grafico pairs()
  # 5.1) Potrei notare che gli outliers possono modificare altamente la scala
       # degli scatter plot, da qui capisco se sono influenti



######## Inference & Prediction ########
########################################

######### Divido in training e test set (vedi appunti) #########

######### Regressione #########
# Parto con il modello lineare della variabile più correlata
