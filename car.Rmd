---
title: "car"
author: "Carbone Giorgio, Scuri Gianluca, Gazzola Michele"
date: "12/11/2021"
output:
  html_document: default
  pdf_document: default
---

# Importazione librerie

```{r importazione librerie e opzioni di rendering, include=FALSE}

library(MASS)
library(readr)
library(tibble)
library(dplyr)
library(stringr)
library(mice)
library(caret)
library(ggcorrplot)
library(GGally) #Per il ggcorr()
library(DiscriMiner) # Per il correlation ratio
library(psych)
library(ggrepel)
library(gridExtra)
library(glmnet)
library(xgboost)
```

# Lettura Dataset

-   Vengono assegnati i fase di lettura i tipi corretti ad ogni variabile
-   Alcune variabili presentano l'unità di misura espressa nel valore, vengono quindi temporanemanente definiti come stringhe

```{r importazione}
data_path <- "https://raw.githubusercontent.com/giocoal/datasets/main/Car%20details%20v3.csv"
car <- read_csv(data_path, col_types = 'ciiiffff????i')
head(data.frame(car))
#View(car)
```

# Obiettivo

L'obiettivo di analisi consiste nella definizione di un modello di regressione lineare multipla che permetta di predire il prezzo di vendita di un'automobile usata, quindi la variabile target sarà `selling_price`.

# Preparazione e pulizia del dataset

#### Scegliamo di non considerare i seguenti attributi

-   Scegliamo di non considerare la colonna mileage (consumi) perchè I consumi delle auto con diverso combustibile non sono comparabili perchè i combustibili hanno un diverso rapporto energia generata/unità di volume
-   L'attributo torque, in quanto calcolato a rpm diversi per ogni veicolo/marca, lo escludiamo dall'analisi

```{r rimozione colonna torque e mileage}
car <- select(car, -c(torque,mileage))
head(car)
```

#### Conversione unità di misura della variabile selling_price

Conversione dell'unità di misura del prezzo di vendita da centesimi di dollaro in dollaro

```{r da centesimo a dollaro}
car$selling_price <- car$selling_price*0.01
```

#### Conversione variabile `year` (anno di produzione) in `age` (anni di vita dell)

Conversione della variabile `year` (anno di produzione) in `age` (anni di vita dell'auto nell'anno di vendita, ovvero il 2021)

```{r conversione year in age}
car <- add_column(car, age = 2021 - car$year, .after = "year")
car <- select(car, -c("year"))
```

#### Introduzione di NA per l'attributo max_power

L'attributo max_power presenta dei missing value in cui però la cella non è vuota ma presenta la sola unità di misura 'bhp'

```{r from 0 to NA}
car$max_power[car$max_power == 0 | car$max_power == "bhp"] <- NA
```

#### Verifico che le unitá di misura di ogni singolo attributo siano consistenti tra loro

```{r Controllo unita di misura}
all(grepl("CC", car$engine) == !is.na(car$engine))
#viene TRUE quindi sono tutti consistenti

all((grepl("bhp", car$max_power)) == !is.na(car$max_power))
#viene TRUE quindi sono tutti consistenti
```

#### Convesione degli attributi in cui i valori sono stringhe contenenti i valori accompagnati dall'unità di misura in valori numerici privi di unità di misura

-   A tale scopo utiliziamo la funzione `parse_value` di `dplyr`

-   Elimino gli attributi contenenti i valori accoppiati alle unità di misura con la funzione `select()` di `dplyr`

```{r Eliminazione unità di misura}
car['engine_CC'] <- parse_number(car$engine)
car['max_power_bhp'] <- parse_number(car$max_power)
car <- select(car, -c('engine', 'max_power'))
```

#### Creazione di una colonna contenente la marca dell'auto

-   Uso la funzione `word` di `dplyr` per estrarre la prima parola del nome dell'auto, la quale coincide con la marca dell'auto.

-   Creo la variabile categoriale `make` che indica la marca dell'auto e la inserisco nel dataset con la funzione `add_column` della libreria `tibble`

```{r colonna marca}
car <- add_column(car, make = factor(word(car$name, 1)), .after = "name")
```

# Statistica descrittiva

## Missing Value

-   Dalla visualizzazione prodotta con l'ausilio della funzione `md.pattern` del pacchetto `mice` notiamo come:

    -   una riga presenta un solo missing value

    -   222 righe presentano tre missing value

-   Essendo le righe contenenti `NA` circa il 3% del delle unità statistiche, decidiamo di rimuoverle

```{r missing value, echo = c(3,6), results = False}
# md.pattern (del pacchetto mice), è una funzione di visualizzazione molto utile
# Permette di vedere la distribuzione di NA nel dataset
md.pattern(car, rotate.names=TRUE)
#numero di righe con almeno un NA (coincide con quanto visto in md.pattern)
# sum(!complete.cases(car))
car <- car[-which(!complete.cases(car)),]
```

## Outliers

Creiamo un subset del dataset contenente le sole variabili quantitative

```{r Estrazione delle variabili numeriche}
car_nums_colnames <- unlist(lapply(car, is.numeric))
car_num <- car[ , car_nums_colnames]
car_num <- select(car_num, -c('seats'))
```

Osserviamo i valori minimi e massimi per ogni attributo quantitativo

```{r}
summary(car_num)
```

Valuto la presenza di outliers nelle variabili quantitative (e, quando presenti, delle rispettive variabili con trasformazione logaritmica) tramite l'osservazione dei *boxplot*.

```{r boxplot per outliers, include = False}
par(mfrow=c(2,3))
#summary(car_num)
for (i in names(car_num)) {
  boxplot(car_num[[i]], xlab = i, main = '')
}
par(mfrow=c(1,1))
```

Tutte le variabili presentano un numero elevato di sospetti outliers. In particolare, tutte le variabili presentano un certo numero di osservazioni classificate come potenziali valori anomali perchè si trovano al di sopra del baffo superiore del boxplot, la cui posizione è definita come $q_{0.75} + 1.5 \cdot IQR$ , dove IQR è il range interquartile. Proviamo a escludere dai potenziali outlier i *mild outlier* e andiamo invece solo a considerare gli *extreme outlier*, aumentando il range di osservazioni incluse nei baffi del boxplot da$I = [q_{0.25} - 1.5 \cdot IQR; q_{0.75} + 1.5 \cdot IQR]$ a $I = [q_{0.25} - 3 \cdot IQR; q_{0.75} + 3 \cdot IQR]$

Inoltre, dato che gli outlier sono solo osservazioni che si trovano al di sopra del baffo superiore dei boxplot, proviamo ad applicare una trasformazione logaritmica.

```{r boxplot log}
par(mfrow=c(2,3))
for (i in names(car_num)) {
  boxplot(log(car_num[[i]]), main = '', xlab = i, range = 3)
}
par(mfrow=c(1,1))

```

Rimuoviamo alcune unità statistiche (lo 0.6% del dataset) contenenti valori anomali particolamente distanti dalle altre osservazioni disponibili.

```{r}
car_num <- car_num[car_num$selling_price < 80000, ]
car_num <- car_num[car_num$engine_CC < 3000, ]
car_num <- car_num[car_num$max_power_bhp < 300, ]
car_num <- car_num[car_num$km_driven < 300000 & car_num$km_driven > 1, ]

car <- car[car$selling_price < 80000, ]
car <- car[car$engine_CC < 3000, ]
car <- car[car$max_power_bhp < 300, ]
car <- car[car$km_driven < 300000 & car$km_driven > 1, ]
```

## Analisi Distribuzionale variabili quantitative

### Fase esplorativa

```{r lettura}
#str(car, give.attr = F)
summary(car)
#class(car)
#dim(car)

```

-   Il dataset ha 8123 unità statistiche e 13 attributi

### Variabile Target: selling_price

La variabile target `selling_price` è quantitativa continua

#### Indicatori Statistici

```{r statistical indicators}
summary(car$selling_price)
```

#### Visualizzazioni e analisi della forma della distribuzione

Osserviamo la distribuzione della variabile target `selling_price` utilizzando come visualizzazione un istogramma. Nel grafico viene inserita una stima della funzione di densità di probabilità ottenuta con il metodo *kernel density estimation (KDE).*

```{r istogramma selling price}
car %>% ggplot()+geom_histogram(aes(selling_price, ..density..), bins = 30, )+geom_density(aes(selling_price))+ggtitle('Istogramma di selling_price (prezzo di vendita auto usate)')+xlab('Selling Price')+ylab('Densità')

#hist(car$selling_price,
#     freq = F,
#     main = "Istogramma di selling_price (prezzo di vendita auto usate)",
#     xlab = "Selling Price",
#     ylab = "Densità",
#     breaks = 237
#     )
```

Valutiamo la simmetria della distribuzione con l'ausilio dell'*indice di simmetria di Pearson* e la curtosi con L'*indice di curtosi di Pearson*

```{r}
print(paste("Indice di asimmetria della variabile response selling_price:", skew(car$selling_price), sep = " "))
print(paste("Indice di curtosi della variabile response selling_price:", kurtosi(car$selling_price), sep = " "))

```

La distribuzione presenta una forte asimmetria positiva, con una coda di destra molto lunga, inoltre essa soffre di un *eccesso di curtosi* (essendo il valore dell'indice di curtosi maggiore di 3)

Proviamo a visualizzare nuovamente la variabile dopo l'applicazione di una trasformazione logaritmica.

```{r istogramma selling_price_log}
car %>% ggplot()+geom_histogram(aes(selling_price, ..density..), bins = 30, )+geom_density(aes(selling_price))+ggtitle('Istogramma del logaritmo di selling_price (prezzo di vendita auto usate)')+xlab('Selling Price')+ylab('Densità')+scale_x_log10()
```

Valutiamo la simmetria e la curtosi della distribuzione dopo l'applicazione della trasformazione logaritmica

```{r simmetria e curtosi log_selling_price}
print(paste("Indice di asimmetria della variabile response selling_price:", skew(log(car$selling_price)), sep = " "))
print(paste("Indice di curtosi della variabile response selling_price:", kurtosi(log(car$selling_price)), sep = " "))
```

La variabile target, in seguito alla trasformazione logaritmica, risulta più simmetrica e non più affetta da eccesso di curtosi, quindi questa sarà trasformata prima di procedere con la fase di inferenza.

### Analisi distribuzione variabili esplicative quantitative

#### Indicatori statistici

```{r indicatori statistici}
summary(car_num)
```

#### Visualizzazioni e analisi della forma della distribuzioni

In modo analogo a quanto fatto con la variabile target, osserviamo la distribuzione delle variabili esplicative quantitative `year`, `km_driven`, `seats`, `engine_CC` e `max_power_bhp`.

```{r istogrammi, include = False}
#istogrammi 
#par(mfrow=c(2,3))
#for (i in names(car_num)) {
#  hist(car_num[[i]], xlab = i, main = '')
#}
#par(mfrow=c(1,1))
#istogrammi

plot1 <- car_num %>% ggplot()+geom_histogram(aes(age, ..density..), bins=15)+geom_density(aes(age))+ylab('')
#print(plot1)

#plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30#)+geom_density(aes(km_driven))+scale_x_continuous(labels = function(x) format(x, scientific #= T))+theme(axis.text.x = element_text(angle = 10))+ylab('')
plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30)+geom_density(aes(km_driven))+scale_x_continuous(labels = function(x) format(x, scientific = F))+ylab('')

#plot3 <- car_num %>% ggplot()+geom_histogram(aes(seats, ..density..), bins=)+geom_density#(aes(seats))+ylab('')
#print(plot3)

plot4 <- car_num %>% ggplot()+geom_histogram(aes(engine_CC, ..density..), bins=30)+geom_density(aes(engine_CC))+ylab('')
#print(plot4)

plot5 <- car_num %>% ggplot()+geom_histogram(aes(max_power_bhp, ..density..), bins=25)+geom_density(aes(max_power_bhp))+ylab('')
#print(plot5)

grid.arrange(plot1, plot2, plot4, plot5, ncol = 2,
             top = "Istogrammi delle distribuzioni delle variabili esplicative quantitative",
             left = "Densità"
             )
```

Calcoliamo l'*indice di asimmetria di Pearson*

```{r indice di asimmetria}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di asimmetria di Pearson di",i,":", skew(car_num[[i]]), sep = " "))
}
```

Calcoliamo l'*indice di curtosi di Pearson,* al fine di quantificare la curtosi ovvero lo 'spessore' delle code delle distribuzioni

```{r indice di curtosi di Pearson}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di curtosi di Pearson di",i,":", kurtosi(car_num[[i]]), sep = " "))
}
```

Traiamo le seguenti conclusioni riguardo la simmetria delle variabili:

-   age: asimmetria positiva
-   km_driven: asimmetria positiva, coda di destra molto pronunciata
-   engine_CC: asimmetria positiva
-   max_power_bhp: asimmetria positiva pronunciata, curtosi pronunciata vicina a una condizione di *eccesso di curtosi*

Valutiamo la forma delle distribuzioni delle variabili esplicative quantitative dopo l'applicazione di una trasformazione logaritmica.

```{r indice di simmetria di Pearson trasformazione logaritmica}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di asimmetria di",i,":", skew(log(car_num[[i]])), sep = " "))
}

```

```{r indice di curtosi di Pearson trasformazione logaritmica}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di curtosi di Pearson di",i,":", kurtosi(log(car_num[[i]])), sep = " "))
}
```

```{r istogrammi log, include = False}
#istogrammi 
#par(mfrow=c(2,3))
#for (i in c('year','selling_price','km_driven','engine(CC)','max_power(bhp)')) {
#  hist(log(car_num[[i]]), xlab = i, main = '')
#}
#par(mfrow=c(1,1))

plot1 <- car_num %>% ggplot()+geom_histogram(aes(age, ..density..), bins=15)+geom_density(aes(age))+ylab('')+scale_x_log10()
#print(plot1)

plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30)+geom_density(aes(km_driven))+theme(axis.text.x = element_text(angle = 10))+ylab('')+scale_x_log10()

#plot3 <- car_num %>% ggplot()+geom_histogram(aes(seats, ..density..), bins=)+geom_density#(aes(seats))+ylab('')+scale_x_log10()
#print(plot3)

plot4 <- car_num %>% ggplot()+geom_histogram(aes(engine_CC, ..density..), bins=30)+geom_density(aes(engine_CC))+ylab('')+scale_x_log10()
#print(plot4)

plot5 <- car_num %>% ggplot()+geom_histogram(aes(max_power_bhp, ..density..), bins=30)+geom_density(aes(max_power_bhp))+ylab('')+scale_x_log10()
#print(plot5)

grid.arrange(plot1, plot2, plot4, plot5, ncol = 2,
             top = "Istogrammi delle distribuzioni delle variabili esplicative quantitative \n dopo l'applicazione della trasformazione logaritmica",
             left = "Densità"
             )
```

Viene applicata la trasformazione logaritmica a `age`, `engine_CC` e `max_power_bhp` perchè applicando la forma della trasformazione logaritmica la distribuzione migliora sia dal punto di vista della simmetria che della curtosi

```{r trasformazione logaritmica}
car <- add_column(car, log_selling_price = log(car$selling_price), .after = "selling_price")
car <- add_column(car, log_age = log(car$age), .after = "age")
car <- add_column(car, log_max_power_bhp = log(car$max_power_bhp), .after = "max_power_bhp")
car <- add_column(car, log_engine_CC = log(car$engine_CC), .after = "engine_CC")

car_num <- add_column(car_num, log_selling_price = log(car_num$selling_price), .after = "selling_price")
car_num <- add_column(car_num, log_age = log(car_num$age), .after = "age")
car_num <- add_column(car_num, log_max_power_bhp = log(car_num$max_power_bhp), .after = "max_power_bhp")
car_num <- add_column(car_num, log_engine_CC = log(car_num$engine_CC), .after = "engine_CC")
```

## Analisi distribuzionale variabili qualitative

### `fuel`: tipo di carburante

```{r tipo di carburante}
# coef = 3 indica la lunghezza dei baffi come multipli dell'IQR (porto da 1.5 a 4)
p <- car %>% ggplot(aes(fuel, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")
print(p)
```

Sono presentati i Boxplot delle distribuzioni di `selling_price` in funzione del tipo di `fuel`. Per ogni distribuzione, mediante l'utilizzo di linee orizzontati sono rappresentati rispettivamente (partendo dal basso) il primo quartile, la mediana e il terzo quartile. Viene inoltre aggiunta, sfruttando `stat_summary` la media, rappresentata da un punto di colore rosso.

Dalle distribuzioni si evince come:

-   in media e in mediana, il prezzo di vendita di una macchina a GPL usata risulti essere il minore. Invece, per le auto a Diesel, si ha una concentrazione di osservazioni a valori di `selling_price` maggiori e un prezzo medio maggiore rispetto a auto con altre tipologie di carburante.

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlaizone fuel}
corRatio(car$log_selling_price, car$fuel)
```

Il valore ottenuto evidenzia dipendenza in media molto leggera.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrato* tra `log_selling_price` e `fuel`:

```{r indice di connessione}
chisq_price_fuel <- chisq.test(car$log_selling_price, car$fuel, simulate.p.value = TRUE)
chisq_price_fuel$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Tipo di proprietario: `owner`

```{r tipo di proprietario}
p1 <- car %>% ggplot(aes(owner, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")+theme(axis.text.x = element_text(angle = 20, hjust = 1))
print(p1)

```

Dalle distribuzioni si evince come:

-   in media e in mediana, il prezzo di vendita di un'automobile usata tenda a diminuire all'aumentare del numero di precedenti proprietari dell'auto (sembra quindi ci sia una dipendenza in media tra `log_selling_price` e `owner`.

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlaizone owner}
corRatio(car$log_selling_price, car$owner)
```

Il valore ottenuto evidenzia una leggera dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrato* tra `log_selling_price` e `owner`:

```{r indice di connessione}
chisq_price_owner <- chisq.test(car$log_selling_price, car$owner, simulate.p.value = TRUE)
chisq_price_owner$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Distribuzione delle marche di auto (`make`)

Visualiziamo la distribuzione delle marche di auto usate vendute con l'ausilio di un grafico a barre, al fine di avere una visualizzazione più agile escludiamo le marche con frequenza assoluta minore di 90.

```{r make boxplot count}
car %>% group_by(make) %>% count() %>% arrange(desc(n)) %>% ggplot() + geom_col(aes(x=n,y=reorder(make,n)), show.legend = F)+
labs(title = 'Distribuzione marche di auto ordinate per frequenza assoluta',
     subtitle = '',
     x= 'Frequenza Assoluta',
     y='make')
```

Osserviamo invece ora la distribuzione di `selling price` condizionata a `make` attraverso dei boxplot. Nei boxplot viene inoltre rappresentata la dispersione dei valori di `selling_price` con lo scopo principale di evidenziareil numero di auto di una specifica marca presenti nel dataset.

```{r selling_price make}
car %>% ggplot(aes(reorder(make, selling_price, median), selling_price))+geom_boxplot()+geom_jitter(alpha=0.02)+geom_hline(aes(yintercept=median(selling_price)))+coord_flip()+xlab('make (marche ordinate per prezzo mediano)')+ylab('selling_price')+theme(aspect.ratio=1)+scale_y_log10()
```

Dalla visualizzazione possiamo dedurre come le auto usate di marche di lusso non abbiano un mercato particolarmente ampio, mentre le marche di auto non di lusso, con un prezzo mediano inferiore, vengono vendute maggiormente.

### Cambio automatico vs cambio manuale: `transmission`

```{r tipo di cambio}
car %>% ggplot(aes(transmission, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")

```

Dalle distribuzioni si evince come:

-   Il numero di auto usate vendute che presentano cambio manuale sia significativamente maggiore di quelle con cambio automatico
-   In media e in mediana, il prezzo di vendita di un'automobile sembra essere maggiore per le auto dotate di cambio automatico (sembra ci sia una dipendenza in media tra la variabile `selling_price` e `transmission`)

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlazione transmission}
corRatio(car$log_selling_price, car$transmission)
```

Il valore ottenuto evidenzia una moderata dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrati* tra `log_selling_price` e `transmission`:

```{r indice di connessione}
chisq_price_transmission <- chisq.test(car$log_selling_price, car$transmission, simulate.p.value = TRUE)
chisq_price_transmission$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Tipo di venditore: `seller_type`

```{r tipo di cambio}
car %>% ggplot(aes(seller_type, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")

```

Dalle distribuzioni si evince come:

-   Il numero di auto usate vendute da privati è maggiore di quelle vendute da dealer (venditore) e da trustmark dealer (venditore con garanzia).
-   In media e in mediana, il prezzo di vendita di un'automobile sembra essere maggiore per le auto dotate di cambio automatico (sembra esserci una certa dipendenza in media tra `log_selling_price` e `seller_type`)

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlazione transmission}
corRatio(car$log_selling_price, car$seller_type)
```

Il valore ottenuto evidenzia una leggera dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrati* tra `log_selling_price` e `seller_type`:

```{r indice di connessione}
chisq_price_seller_type <- chisq.test(car$log_selling_price, car$seller_type, simulate.p.value = TRUE)
chisq_price_transmission$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

## Analisi delle correlazioni

Visualizzo possibili correlazioni osservando i *pair plots* (diagrammi a dispersione accoppiati) tra le variabil quantitative.\
Al fine di rendere più agile la rappresentazione grafica viene selezionato tramite *simple random sampling* un campione di 500 unità statistiche del dataset originale.

```{r correlazioni}
# Aggiorno il vettore delle colonne numeriche di car
car_nums_colnames_log <- c('log_age','log_selling_price','km_driven','log_engine_CC','log_max_power_bhp', 'seats')
# Prendo un campione di osservazioni per rendere più agile la rappresentazione grafica:
leggero <- car[sample(nrow(car), 500), ]
# Matrice dei diagrammi di dispersione: (non serve usare le variabili trasformate perchè la correlazione non cambia)
pairs(leggero[, car_nums_colnames_log])
cor(car[ ,car_nums_colnames_log])
```

Al fine di evidenziare le correlazioni osservo i *coefficienti di correlazione di Pearson*

```{r Pearson}
ggcorr(car[,car_nums_colnames_log], label = TRUE, label_size = 2.9, hjust = 1, layout.exp = 2)

```

Osservando i *coefficienti di correlazione di Pearson* deduciamo che la variabile target `log_selling_price` presenza:

-   Debole associazione positiva con la variabile `seats`

-   Debole associazione negativa con la variabile `km_driven`

-   Moderata associazione positiva con la variabile `log_engine_CC`

-   **Forte associazione positiva** con la variabile `log_max_power_bhp` (0.7)

-   **Forte associazione negativa** con la variabile `log_age` (-0.7)

Per quanto riguarda le associazioni tra le variabili esplicative, si evidenziano alcuni problemi collegati a una probabile **multicollinarità**:

-   `seats` presenta forte associazione positiva con `log_engine_CC`

    -   successivamente escluderemo `seats` dalla stima del modello di regressione perché tra le due è la meno correlata con `selling_price`

-   `log_max_power_bhp` presenta forte associazione positiva con `log_engine_CC`

    -   successivamente escluderemo `log_engine_CC` dalla stima del modello di regressione perché tra le due è la meno correlata con `selling_price`

-   `km_driven` presenta una moderata associazione con `log_age`

# Statistica inferenziale

```{r cose da fare}

#T TEST
#Variable importance
#F TEST
#Adjusted R-squared
#Residual analysis
#(compare two models with anova)

#Prediction RMSE
```

## Preparazione

Creo un nuovo dataset chiamato `car_dummy` al quale aggiungo le variabili quantitative in forma logaritmica dove necessario. Successivamente elimino gli attributi che sono molto correlati con gli altri presenti e poco correlati con la variabile target (`log_engine_CC` e `seats`).

```{r subset delle variabili quantitative}

car_dummy <- car[,car_nums_colnames_log]
car_dummy <- select(car_dummy, -c('seats', 'log_engine_CC'))
```

### Variabili dummy

Al dataset appena creato aggiungo le colonne relative alle variabili categoriche. Per ogni attributo vengono generate n-1 nuove colonne dove n è il numero di modalità di quel particolare attributo.

```{r da variabili fattoriali a variabili dummy}

# Aggiungo la variabile fattoriale 'transmission' a car dummy e la converto in numerica (0 corrispode a 'automatic'):
car_dummy <- cbind(car_dummy,transmission = car$transmission)
levels(car_dummy$transmission)<-c(1,0)
car_dummy$transmission <- as.numeric(levels(car_dummy$transmission))[car_dummy$transmission]

#converto la variabile fattoriale 'make' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~make, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'fuel' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~fuel, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'seller_type' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~seller_type, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'owner' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~owner, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

head(car_dummy)
```

### Righe duplicate nel dataset

Individuo il numero di righe uguali nel dataset.

```{r}
sum(duplicated(car_dummy))
```

Le righe uguali sono molte ma decidiamo di lasciarle poiché anch'esse portano informazione. Infatti due auto uguali vendute allo stesso prezzo devono avere un peso doppio rispetto ad una riga unica.

### Training e Test sets

Divido il nuovo dataset creato al punto precedente in due con rapporto 80 20 così da poter allenare il modello sulla partizione più grande (`train_set`) e poterlo poi verificare su quello piú piccolo (`test_set`).

```{r split dataset in Training e Test sets}
set.seed(100)
train_ind<-sample(1:nrow(car_dummy),0.8*nrow(car_dummy))

train_set <- car_dummy[train_ind,]
test_set <- car_dummy[-train_ind,]
```

Verifico le dimensioni dei due nuovi dataset.

```{r dimensioni train_set e test_set}
cat("Numero righe train_set = ", nrow(train_set), "\n")
cat("Numero righe test_set  = ", nrow(test_set))
```

## Regressione lineare

Come primo passo realizzo un modello di regressione, sul `train_set` in cui considero tutte le 45 variabili

```{r modello completo}
modello_completo <- lm(log_selling_price ~ ., data=train_set)
summary(modello_completo)
```

Ciò che risulta è un modello con un valore dell'R quadro aggiustato elevato `R-squared: 0.8901`. Il problema di questo modello però è che molti degli attributi non sono significativi e alcuni di questi sono collineari, quindi probabilmente il valore R alto è dovuto ad un fenomeno di overfitting. Questa cosa la verificheremo poi nella sezione successiva in cui testeremo i risultati sul test set.

Dalla tabella dei coefficienti si può osservare anche che, dei molti attributi dovuti alla marca dell'auto, quelli che presentano la significatività maggiore sono quelli corrispondenti alle macchine più lussuose. Questa cosa è dovuta al fatto che il prezzo di queste auto si discosta molto dalla maggior parte delle altre auto a parità di motore e utilizzo, in fase di valutazione del prezzo è quindi un parametro da tenere in considerazione.

```{r plot modello completo}
par(mfrow=c(2,2))
plot(modello_completo) #da sistemare warning
par(mfrow=c(1,1))
```

#commento plot

Da questi grafici si vede che effettivamente ci sono dei problemi nel modello, in particolare nel `Normal Q-Q` si vede gli `Strandardized residual` a sinistra (con `Theoretical Quantiles` tra -4 e -2) siano piú bassi del valore teorico. Anche nel grafico della `Scale-Location` si vedono delle anomalie

### Feature selection

Cerchiamo ora di ridurre il numero di attributi necessari per aumentare l'interpretabilità e tentare di ridurre i problemi presenti.

Guardando la tabella delle correlazioni della sezione "Analisi delle correlazioni" è facile notare come `log_max_power_bhp` e `log_age` siano i due attributi più correlati con `log_selling_price` rispettivamente con valore di `0.74` e `0.67`. Scegliamo quindi `log_max_power_bhp` come primo attributo con cui costruire il modello.

```{r primo modello con solo log_max_power_bhp}
modello_minimo <- lm(log_selling_price ~ log_max_power_bhp, data=train_set)
summary(modello_minimo)
```

Come ci aspettavamo l'attributo `log_max_power_bhp` è molto significativo per la descrizione del modello con un p-value molto basso e un R quadro comunque abbastanza elevato `Adjusted R-squared:  0.5493.` Vediamo ora qui di seguito la rappresentazione grafica della retta trovata.

```{r grafico modello semplificato}
ggplot(train_set, aes(x = log_max_power_bhp, y = log_selling_price)) + geom_point() + stat_smooth(method = "lm", col = "red")
```

Cerchiamo ora di raffinare il modello andando ad includere un numero maggiore di attributi. Per farlo eseguiamo un processo di forward selection; dato il grande numero di attributi presentisfruttiamo la funzione stepAIC.

In prima battuta utilizziamo il `modello_minimo` appena realizzato, settiamo `direction = "forward"` e indichiamo come scope il `modello_completo`.

```{r modello stepAIC, include=FALSE, results='hide'}
modello_stepAIC <- stepAIC(modello_minimo, direction = "forward", scope = formula(modello_completo))
```

Visto il grande numero di passaggi necessari nascondiamo l'output e riportiamo i risultati di seguito:

`formula = log_selling_price ~ log_max_power_bhp + log_age + fuelPetrol + makeTata + transmission + makeToyota + makeChevrolet + km_driven + makeBMW + makeLexus + makeJaguar + makeMercedes.Benz + ownerFourth…Above.Owner + ownerThird.Owner + ownerSecond.Owner + makeVolvo + makeAudi + makeFord + makeDatsun + makeLand + fuelCNG + makeFiat + makeMaruti + makeMahindra + seller_typeDealer + fuelLPG + makeVolkswagen + makeDaewoo + ownerTest.Drive.Car + makeKia + makeMitsubishi + makeHonda + makeJeep + makeOpel + seller_typeTrustmark.Dealer + makeHyundai`

Il processo di stepAIC ha portato all'esclusione di 7 attributi tutti legati alla marche dei veicoli: `makeMG, makeForce, makeIsuzu, makeSkoda, makeNissan, makeRenault, makeAshok`. Verifico a questo punto i parametri di questo nuovo modello.

```{r risultato modello stepAIC}
summary(modello_stepAIC)
```

La rimozione di quelli attributi ha portato il valore dell'R quadro aggiustato a `Adjusted R-squared:  0.8901`, cioè identico a quello iniziale. Togliendo quelle colonne abbiamo quindi alleggerito il modello senza perdere di performance.

Andiamo allora a graficare le caratteristiche di questo nuovo modello.

```{r plot modello stepAIC}
par(mfrow=c(2,2))
plot(modello_stepAIC)
par(mfrow=c(1,1))
```

#commenti grafici

Nel modello sono presenti però ancora diversi attributi che sarebbe meglio rimuovere poiché poco significativi. Procediamo allora nuovamente ad utilizzare la funzione stepAIC settando il parametro k, che limita la significativitá dei parametri, ad un valore corrispondente a `0.001`. Per calcolare il valore di k fruttiamo la funzione `qchisq`.

```{r valore di k da significativitá minima}
k_value <- qchisq(0.001, 1, lower.tail = F)
```

```{r modello stepAIC con parametro k, include=FALSE, results='hide'}
modello_stepAIC_k <- stepAIC(modello_minimo, direction = "forward", scope = formula(modello_completo), k = k_value)
```

Anche in questo caso nascondiamo l'output e riportiamo solo il risultato.

`formula = log_selling_price ~ log_max_power_bhp + log_age + fuelPetrol + makeTata + transmission + makeToyota + makeChevrolet + km_driven + makeBMW + makeLexus + makeJaguar + makeMercedes.Benz + ownerFourth…Above.Owner + ownerThird.Owner + ownerSecond.Owner + makeVolvo + makeAudi + makeFord + makeDatsun + makeLand + fuelCNG + makeFiat + makeMaruti + makeMahindra`

Risultano quindi esclusi dal modello 19 attributi: `seller_typeDealer, fuelLPG, makeVolkswagen, makeDaewoo, ownerTest.Drive.Car, makeHonda, makeMitsubishi, makeKia, makeOpel, makeJeep, seller_typeTrustmark.Dealer, makeMG, makeRenault, makeForce, makeSkoda, makeNissan, makeIsuzu, makeHyundai, makeAshok`.

Procediamo a verificare il valore dell'R quadro del nuovo modello.

```{r risultato modello stepAIC con parametro k}
summary(modello_stepAIC_k)
```

Il modello è ora composto da 26 attributi molto significativi, il valore dell'R quadro aggiustato é `Adjusted R-squared:  0.8891`, cioè praticamente identico a quello individuato in precedenza.

Anche in questo caso andiamo a mostrare i grafici dei residui del modello trovato.

```{r plot modello stepAIC con parametro k}
par(mfrow=c(2,2))
plot(modello_stepAIC_k)
par(mfrow=c(1,1))
```

#commento grafico

Procediamo ora con il test F. Utilizzando ora la funzione Anova confrontiamo il modello ottenuto con la funzione stepAIC e quello ottenuto dal processo di stepAIC con parametro k per vedere se la rimozione degli attributi meno significativi con l'uso del parametro k è giustificata.

```{r confronto modello_stepAIC con modello_stepAIC_k}
anova(modello_stepAIC, modello_stepAIC_k)
```

#verificare se é accettabile quel valore di F

### Analisi dei residui

## Verifico il modello applicandolo al test set

### rmse modello con tutti i parametri

### rmse modello scelto
