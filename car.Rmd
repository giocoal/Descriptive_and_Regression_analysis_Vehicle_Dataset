---
title: "car"
author: "Carbone Giorgio, Scuri Gianluca, Gazzola Michele"
date: "12/11/2021"
output:
  html_document: default
  pdf_document: default
---

# Importazione librerie

```{r importazione librerie e opzioni di rendering, include=FALSE}

library(readr)
library(tibble)
library(dplyr)
library(stringr)
library(mice)
library(caret)
library(ggcorrplot)
library(GGally) #Per il ggcorr()
library(DiscriMiner) # Per il correlation ratio
library(psych)
library(ggrepel)
library(gridExtra)
library(glmnet)
library(xgboost)
```

# Lettura Dataset

-   Vengono assegnati i fase di lettura i tipi corretti ad ogni variabile
-   Alcune variabili presentano l'unità di misura espressa nel valore, vengono quindi temporanemanente definiti come stringhe

```{r importazione}
data_path <- "https://raw.githubusercontent.com/giocoal/datasets/main/Car%20details%20v3.csv"
car <- read_csv(data_path, col_types = 'ciiiffff????i')
head(data.frame(car))
View(car)
```

# Obiettivo

L'obiettivo di analisi consiste nella definizione di un modello di regressione lineare multipla che permetta di predire il prezzo di vendita di un'automobile usata.

# Preparazione e pulizia del dataset

#### Scegliamo di non considerare i seguenti attributi

-   Scegliamo di non considerare la colonna mileage (consumi) perchè I consumi delle auto con diverso combustibile non sono comparabili perchè i combustibili hanno un diverso rapporto energia generata/unità di volume
-   L'attributo torque, in quanto calcolato a rpm diversi per ogni veicolo/marca, lo escludiamo dall'analisi

```{r rimozione colonna torque e mileage}
car <- select(car, -c(torque,mileage))
head(car)
```

#### Conversione unità di misura della variabile selling_price

Conversione dell'unità di misura del prezzo di vendita da centesimi di dollaro in dollaro

```{r da centesimo a dollaro}
car$selling_price <- car$selling_price*0.01
```

#### Conversione variabile `year` (anno di produzione) in `age` (anni di vita dell)

Conversione della variabile `year` (anno di produzione) in `age` (anni di vita dell'auto nell'anno di vendita, ovvero il 2021)

```{r conversione year in age}
car <- add_column(car, age = 2021 - car$year, .after = "year")
car <- select(car, -c("year"))
```

#### Introduzione di NA per l'attributo max_power

L'attributo max_power presenta dei missing value in cui però la cella non è vuota ma presenta la sola unità di misura 'bhp'

```{r from 0 to NA}
car$max_power[car$max_power == 0 | car$max_power == "bhp"] <- NA
```

#### Verifico che le unitá di misura di ogni singolo attributo siano consistenti tra loro

```{r Controllo unita di misura}
all(grepl("CC", car$engine) == !is.na(car$engine))
#viene TRUE quindi sono tutti consistenti

all((grepl("bhp", car$max_power)) == !is.na(car$max_power))
#viene TRUE quindi sono tutti consistenti
```

#### Convesione degli attributi in cui i valori sono stringhe contenenti i valori accompagnati dall'unità di misura in valori numerici privi di unità di misura

-   A tale scopo utiliziamo la funzione `parse_value` di `dplyr`

-   Elimino gli attributi contenenti i valori accoppiati alle unità di misura con la funzione `select()` di `dplyr`

```{r Eliminazione unità di misura}
car['engine_CC'] <- parse_number(car$engine)
car['max_power_bhp'] <- parse_number(car$max_power)
car <- select(car, -c('engine', 'max_power'))
```

#### Creazione di una colonna contenente la marca dell'auto

-   Uso la funzione `word` di `dplyr` per estrarre la prima parola del nome dell'auto, la quale coincide con la marca dell'auto.

-   Creo la variabile categoriale `make` che indica la marca dell'auto e la inserisco nel dataset con la funzione `add_column` della libreria `tibble`

```{r colonna marca}
car <- add_column(car, make = factor(word(car$name, 1)), .after = "name")
```

# Statistica descrittiva

## Missing Value

-   Dalla visualizzazione prodotta con l'ausilio della funzione `md.pattern` del pacchetto `mice` notiamo come:

    -   una riga presenta un solo missing value

    -   222 righe presentano tre missing value

-   Essendo le righe contenenti `NA` circa il 3% del delle unità statistiche, decidiamo di rimuoverle

```{r missing value, echo = c(3,6), results = False}
# md.pattern (del pacchetto mice), è una funzione di visualizzazione molto utile
# Permette di vedere la distribuzione di NA nel dataset
md.pattern(car, rotate.names=TRUE)
#numero di righe con almeno un NA (coincide con quanto visto in md.pattern)
# sum(!complete.cases(car))
car <- car[-which(!complete.cases(car)),]
```

## Outliers

Creiamo un subset del dataset contenente le sole variabili quantitative

```{r Estrazione delle variabili numeriche}
car_nums_colnames <- unlist(lapply(car, is.numeric))
car_num <- car[ , car_nums_colnames]
car_num <- select(car_num, -c('seats'))
```

Osserviamo i valori minimi e massimi per ogni attributo quantitativo

```{r}
summary(car_num)
```

Valuto la presenza di outliers nelle variabili quantitative (e, quando presenti, delle rispettive variabili con trasformazione logaritmica) tramite l'osservazione dei *boxplot*.

```{r boxplot per outliers, include = False}
par(mfrow=c(2,3))
#summary(car_num)
for (i in names(car_num)) {
  boxplot(car_num[[i]], xlab = i, main = '')
}
par(mfrow=c(1,1))
```

Tutte le variabili presentano un numero elevato di sospetti outliers. In particolare, tutte le variabili presentano un certo numero di osservazioni classificate come potenziali valori anomali perchè si trovano al di sopra del baffo superiore del boxplot, la cui posizione è definita come $q_{0.75} + 1.5 \cdot IQR$ , dove IQR è il range interquartile. Proviamo a escludere dai potenziali outlier i *mild outlier* e andiamo invece solo a considerare gli *extreme outlier*, aumentando il range di osservazioni incluse nei baffi del boxplot da$I = [q_{0.25} - 1.5 \cdot IQR; q_{0.75} + 1.5 \cdot IQR]$ a $I = [q_{0.25} - 3 \cdot IQR; q_{0.75} + 3 \cdot IQR]$

Inoltre, dato che gli outlier sono solo osservazioni che si trovano al di sopra del baffo superiore dei boxplot, proviamo ad applicare una trasformazione logaritmica.

```{r boxplot log}
par(mfrow=c(2,3))
for (i in names(car_num)) {
  boxplot(log(car_num[[i]]), main = '', xlab = i, range = 3)
}
par(mfrow=c(1,1))

```

Rimuoviamo alcune unità statistiche (lo 0.6% del dataset) contenenti valori anomali particolamente distanti dalle altre osservazioni disponibili.

```{r}
car_num <- car_num[car_num$selling_price < 80000, ]
car_num <- car_num[car_num$engine_CC < 3000, ]
car_num <- car_num[car_num$max_power_bhp < 300, ]
car_num <- car_num[car_num$km_driven < 300000 & car_num$km_driven > 1, ]

car <- car[car$selling_price < 80000, ]
car <- car[car$engine_CC < 3000, ]
car <- car[car$max_power_bhp < 300, ]
car <- car[car$km_driven < 300000 & car$km_driven > 1, ]
```

## Analisi Distribuzionale variabili quantitative

### Fase esplorativa

```{r lettura}
#str(car, give.attr = F)
summary(car)
#class(car)
#dim(car)

```

-   Il dataset ha 8123 unità statistiche e 13 attributi
-   Individuiamo come variabile target la variabile quantitativa continua `selling_price`

### Variabile Target: selling_price

#### Indicatori Statistici

```{r statistical indicators}
summary(car$selling_price)
```

#### Visualizzazioni e analisi della forma della distribuzione

Osserviamo la distribuzione della variabile target `selling_price` utilizzando come visualizzazione un istogramma. Nel grafico viene inserita una stima della funzione di densità di probabilità ottenuta con il metodo *kernel density estimation (KDE).*

```{r istogramma selling price}
car %>% ggplot()+geom_histogram(aes(selling_price, ..density..), bins = 30, )+geom_density(aes(selling_price))+ggtitle('Istogramma di selling_price (prezzo di vendita auto usate)')+xlab('Selling Price')+ylab('Densità')

#hist(car$selling_price,
#     freq = F,
#     main = "Istogramma di selling_price (prezzo di vendita auto usate)",
#     xlab = "Selling Price",
#     ylab = "Densità",
#     breaks = 237
#     )
```

Valutiamo la simmetria della distribuzione con l'ausilio dell'*indice di simmetria di Pearson* e la curtosi con L'*indice di curtosi di Pearson*

```{r}
print(paste("Indice di asimmetria della variabile response selling_price:", skew(car$selling_price), sep = " "))
print(paste("Indice di curtosi della variabile response selling_price:", kurtosi(car$selling_price), sep = " "))

```

La distribuzione presenta una forte asimmetria positiva, con una coda di destra molto lunga, inoltre essa soffre di un *eccesso di curtosi* (essendo il valore dell'indice di curtosi maggiore di 3)

Proviamo a visualizzare nuovamente la variabile dopo l'applicazione di una trasformazione logaritmica.

```{r istogramma selling_price_log}
car %>% ggplot()+geom_histogram(aes(selling_price, ..density..), bins = 30, )+geom_density(aes(selling_price))+ggtitle('Istogramma del logaritmo di selling_price (prezzo di vendita auto usate)')+xlab('Selling Price')+ylab('Densità')+scale_x_log10()
```

Valutiamo la simmetria e la curtosi della distribuzione dopo l'applicazione della trasformazione logaritmica

```{r simmetria e curtosi log_selling_price}
print(paste("Indice di asimmetria della variabile response selling_price:", skew(log(car$selling_price)), sep = " "))
print(paste("Indice di curtosi della variabile response selling_price:", kurtosi(log(car$selling_price)), sep = " "))
```

La variabile target, in seguito alla trasformazione logaritmica, risulta più simmetrica e non più affetta da eccesso di curtosi, quindi questa sarà trasformata prima di procedere con la fase di inferenza.

### Analisi distribuzione variabili esplicative quantitative

#### Indicatori statistici

```{r indicatori statistici}
summary(car_num)
```

#### Visualizzazioni e analisi della forma della distribuzioni

In modo analogo a quanto fatto con la variabile target, osserviamo la distribuzione delle variabili esplicative quantitative `year`, `km_driven`, `seats`, `engine_CC` e `max_power_bhp`.

```{r istogrammi, include = False}
#istogrammi 
#par(mfrow=c(2,3))
#for (i in names(car_num)) {
#  hist(car_num[[i]], xlab = i, main = '')
#}
#par(mfrow=c(1,1))
#istogrammi

plot1 <- car_num %>% ggplot()+geom_histogram(aes(age, ..density..), bins=15)+geom_density(aes(age))+ylab('')
#print(plot1)

#plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30#)+geom_density(aes(km_driven))+scale_x_continuous(labels = function(x) format(x, scientific #= T))+theme(axis.text.x = element_text(angle = 10))+ylab('')
plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30)+geom_density(aes(km_driven))+scale_x_continuous(labels = function(x) format(x, scientific = F))+ylab('')

#plot3 <- car_num %>% ggplot()+geom_histogram(aes(seats, ..density..), bins=)+geom_density#(aes(seats))+ylab('')
#print(plot3)

plot4 <- car_num %>% ggplot()+geom_histogram(aes(engine_CC, ..density..), bins=30)+geom_density(aes(engine_CC))+ylab('')
#print(plot4)

plot5 <- car_num %>% ggplot()+geom_histogram(aes(max_power_bhp, ..density..), bins=25)+geom_density(aes(max_power_bhp))+ylab('')
#print(plot5)

grid.arrange(plot1, plot2, plot4, plot5, ncol = 2,
             top = "Istogrammi delle distribuzioni delle variabili esplicative quantitative",
             left = "Densità"
             )
```

Calcoliamo l'*indice di asimmetria di Pearson*

```{r indice di asimmetria}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di asimmetria di Pearson di",i,":", skew(car_num[[i]]), sep = " "))
}
```

Calcoliamo l'*indice di curtosi di Pearson,* al fine di quantificare la curtosi ovvero lo 'spessore' delle code delle distribuzioni

```{r indice di curtosi di Pearson}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di curtosi di Pearson di",i,":", kurtosi(car_num[[i]]), sep = " "))
}
```

Traiamo le seguenti conclusioni riguardo la simmetria delle variabili:

-   age: asimmetria positiva
-   km_driven: asimmetria positiva, coda di destra molto pronunciata
-   engine_CC: asimmetria positiva
-   max_power_bhp: asimmetria positiva pronunciata, curtosi pronunciata vicina a una condizione di *eccesso di curtosi*

Valutiamo la forma delle distribuzioni delle variabili esplicative quantitative dopo l'applicazione di una trasformazione logaritmica.

```{r indice di simmetria di Pearson trasformazione logaritmica}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di asimmetria di",i,":", skew(log(car_num[[i]])), sep = " "))
}

```

```{r indice di curtosi di Pearson trasformazione logaritmica}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di curtosi di Pearson di",i,":", kurtosi(log(car_num[[i]])), sep = " "))
}
```

```{r istogrammi log, include = False}
#istogrammi 
#par(mfrow=c(2,3))
#for (i in c('year','selling_price','km_driven','engine(CC)','max_power(bhp)')) {
#  hist(log(car_num[[i]]), xlab = i, main = '')
#}
#par(mfrow=c(1,1))

plot1 <- car_num %>% ggplot()+geom_histogram(aes(age, ..density..), bins=15)+geom_density(aes(age))+ylab('')+scale_x_log10()
#print(plot1)

plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30)+geom_density(aes(km_driven))+theme(axis.text.x = element_text(angle = 10))+ylab('')+scale_x_log10()

#plot3 <- car_num %>% ggplot()+geom_histogram(aes(seats, ..density..), bins=)+geom_density#(aes(seats))+ylab('')+scale_x_log10()
#print(plot3)

plot4 <- car_num %>% ggplot()+geom_histogram(aes(engine_CC, ..density..), bins=30)+geom_density(aes(engine_CC))+ylab('')+scale_x_log10()
#print(plot4)

plot5 <- car_num %>% ggplot()+geom_histogram(aes(max_power_bhp, ..density..), bins=30)+geom_density(aes(max_power_bhp))+ylab('')+scale_x_log10()
#print(plot5)

grid.arrange(plot1, plot2, plot4, plot5, ncol = 2,
             top = "Istogrammi delle distribuzioni delle variabili esplicative quantitative \n dopo l'applicazione della trasformazione logaritmica",
             left = "Densità"
             )
```

Viene applicata la trasformazione logaritmica a `age`, `engine_CC` e `max_power_bhp` perchè applicando la forma della trasformazione logaritmica la distribuzione migliora sia dal punto di vista della simmetria che della curtosi

```{r trasformazione logaritmica}
car <- add_column(car, log_selling_price = log(car$selling_price), .after = "selling_price")
car <- add_column(car, log_age = log(car$age), .after = "age")
car <- add_column(car, log_max_power_bhp = log(car$max_power_bhp), .after = "max_power_bhp")
car <- add_column(car, log_engine_CC = log(car$engine_CC), .after = "engine_CC")

car_num <- add_column(car_num, log_selling_price = log(car_num$selling_price), .after = "selling_price")
car_num <- add_column(car_num, log_age = log(car_num$age), .after = "age")
car_num <- add_column(car_num, log_max_power_bhp = log(car_num$max_power_bhp), .after = "max_power_bhp")
car_num <- add_column(car_num, log_engine_CC = log(car_num$engine_CC), .after = "engine_CC")
```

## Analisi distirbuzionale variabili qualitative

### `fuel`: tipo di carburante

```{r tipo di carburante}
# coef = 3 indica la lunghezza dei baffi come multipli dell'IQR (porto da 1.5 a 4)
p <- car %>% ggplot(aes(fuel, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")
print(p)
```

Sono presentati i Boxplot delle distribuzioni di `selling_price` in funzione del tipo di `fuel`. Per ogni distribuzione, mediante l'utilizzo di linee orizzontati sono rappresentati rispettivamente (partendo dal basso) il primo quartile, la mediana e il terzo quartile. Viene inoltre aggiunta, sfruttando `stat_summary` la media, rappresentata da un punto di colore rosso.

Dalle distribuzioni si evince come:

-   in media e in mediana, il prezzo di vendita di una macchina a GPL usata risulti essere il minore. Invece, per le auto a Diesel, si ha una concentrazione di osservazioni a valori di `selling_price` maggiori e un prezzo medio maggiore rispetto a auto con altre tipologie di carburante.

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlaizone fuel}
corRatio(car$log_selling_price, car$fuel)
```

Il valore ottenuto evidenzia dipendenza in media molto leggera.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrato* tra `log_selling_price` e `fuel`:

```{r indice di connessione}
chisq_price_fuel <- chisq.test(car$log_selling_price, car$fuel, simulate.p.value = TRUE)
chisq_price_fuel$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Tipo di proprietario: `owner`

```{r tipo di proprietario}
p1 <- car %>% ggplot(aes(owner, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")+theme(axis.text.x = element_text(angle = 20, hjust = 1))
print(p1)

```

Dalle distribuzioni si evince come:

-   in media e in mediana, il prezzo di vendita di un'automobile usata tenda a diminuire all'aumentare del numero di precedenti proprietari dell'auto (sembra quindi ci sia una dipendenza in media tra `log_selling_price` e `owner`.

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlaizone owner}
corRatio(car$log_selling_price, car$owner)
```

Il valore ottenuto evidenzia una leggera dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrato* tra `log_selling_price` e `owner`:

```{r indice di connessione}
chisq_price_owner <- chisq.test(car$log_selling_price, car$owner, simulate.p.value = TRUE)
chisq_price_owner$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Distribuzione delle marche di auto (`make`)

Visualiziamo la distribuzione delle marche di auto usate vendute con l'ausilio di un grafico a barre, al fine di avere una visualizzazione più agile escludiamo le marche con frequenza assoluta minore di 90.

```{r make boxplot count}
car %>% group_by(make) %>% count() %>% arrange(desc(n)) %>% ggplot() + geom_col(aes(x=n,y=reorder(make,n)), show.legend = F)+
labs(title = 'Distribuzione marche di auto ordinate per frequenza assoluta',
     subtitle = '',
     x= 'Frequenza Assoluta',
     y='make')
```

Osserviamo invece ora la distribuzione di `selling price` condizionata a `make` attraverso dei boxplot. Nei boxplot viene inoltre rappresentata la dispersione dei valori di `selling_price` con lo scopo principale di evidenziareil numero di auto di una specifica marca presenti nel dataset.

```{r selling_price make}
car %>% ggplot(aes(reorder(make, selling_price, median), selling_price))+geom_boxplot()+geom_jitter(alpha=0.02)+geom_hline(aes(yintercept=median(selling_price)))+coord_flip()+xlab('make (marche ordinate per prezzo mediano)')+ylab('selling_price')+theme(aspect.ratio=1)+scale_y_log10()
```

Dalla visualizzazione possiamo dedurre come le auto usate di marche di lusso non abbiano un mercato particolarmente ampio, mentre le marche di auto non di lusso, con un prezzo mediano inferiore, vengono vendute maggiormente.

### Tipo di proprietario: `transmission`

```{r tipo di cambio}
car %>% ggplot(aes(transmission, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")

```

Dalle distribuzioni si evince come:

-   Il numero di auto usate vendute che presentano cambio manuale sia significativamente maggiore di quelle con cambio automatico
-   In media e in mediana, il prezzo di vendita di un'automobile sembra essere maggiore per le auto dotate di cambio automatico (sembra ci sia una dipendenza in media tra la variabile `selling_price` e `transmission`)

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlaizone transmission}
corRatio(car$log_selling_price, car$transmission)
```

Il valore ottenuto evidenzia una moderata dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrati* tra `log_selling_price` e `transmission`:

```{r indice di connessione}
chisq_price_transmission <- chisq.test(car$log_selling_price, car$transmission, simulate.p.value = TRUE)
chisq_price_transmission$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Tipo di venditore: `seller_type`

```{r tipo di cambio}
car %>% ggplot(aes(seller_type, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")

```

Dalle distribuzioni si evince come:

-   Il numero di auto usate vendute che presentano cambio manuale sia significativamente maggiore di quelle con cambio automatico
-   In media e in mediana, il prezzo di vendita di un'automobile sembra essere maggiore per le auto dotate di cambio automatico (sembra esserci una certa dipendenza in media tra `log_selling_price` e `seller_type`)

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlazione transmission}
corRatio(car$log_selling_price, car$seller_type)
```

Il valore ottenuto evidenzia una leggera dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrati* tra `log_selling_price` e `seller_type`:

```{r indice di connessione}
chisq_price_seller_type <- chisq.test(car$log_selling_price, car$seller_type, simulate.p.value = TRUE)
chisq_price_transmission$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

## Analisi delle correlazioni

Visualizzo possibili correlazioni osservando i *pair plots* (diagrammi a dispersione accoppiati) tra le variabil quantitative.\
Al fine di rendere più agile la rappresentazione grafica viene selezionato tramite *simple random sampling* un campione di 500 unità statistiche del dataset originale.

```{r correlazioni}
# Aggiorno il vettore delle colonne numeriche di car
car_nums_colnames_log <- c('log_age','log_selling_price','km_driven','log_engine_CC','log_max_power_bhp', 'seats')
# Prendo un campione di osservazioni per rendere più agile la rappresentazione grafica:
leggero <- car[sample(nrow(car), 500), ]
# Matrice dei diagrammi di dispersione: (non serve usare le variabili trasformate perchè la correlazione non cambia)
pairs(leggero[, car_nums_colnames_log])
cor(car[ ,car_nums_colnames_log])
```

Al fine di evidenziare le correlazioni osservo i *coefficienti di correlazione di Pearson*

```{r Pearson}
ggcorr(car[,car_nums_colnames_log], label = TRUE, label_size = 2.9, hjust = 1, layout.exp = 2)

```

Osservando i *coefficienti di correlazione di Pearson* deduciamo che la variabile target `log_selling_price` presenza:

-   Debole associazione positiva con la variabile `seats`

-   Debole associazione negativa con la variabile `km_driven`

-   Moderata associazione positiva con la variabile `log_engine_CC`

-   **Forte associazione positiva** con la variabile `log_max_power_bhp` (0.7)

-   **Forte associazione negativa** con la variabile `log_age` (-0.7)

Per quanto riguarda le associazioni tra le variabili esplicative, si evidenziano alcuni problemi collegati a una probabile **multicollinarità**:

-   `seats` presenta forte associazione positiva con `log_engine_CC`

-   `log_max_power_bhp` presenta forte associazione positiva con `log_engine_CC`

-   `km_driven` presenta una moderata associazione con `log_age`

# Statistica inferenziale

## Preparazione

### Variabili dummy

```{r da variabili fattoriali a variabili dummy}

car_dummy <- car_num

# Aggiungo la variabile fattoriale 'transmission' a car dummy e la converto in numerica (0 corrispode a 'automatic'):
car_dummy <- cbind(car_dummy,transmission = car$transmission)
levels(car_dummy$transmission)<-c(1,0)
car_dummy$transmission <- as.numeric(levels(car_dummy$transmission))[car_dummy$transmission]

#converto la variabile fattoriale 'make' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~make, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'fuel' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~fuel, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'seller_type' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~seller_type, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'owner' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~owner, data = car))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

head(car_dummy)
```

### Training e Test sets

```{r split dataset in Training e Test sets}
set.seed(100)
train_ind<-sample(1:nrow(car_dummy),0.8*nrow(car_dummy))

train_set<-car_dummy[train_ind,]
test_set <-car_dummy[-train_ind,]
```

\#applico un'analisi di regressione fra year e selling price

```{r analisi di regressione fra le colonne year e selling price}
car1<-car[,c(3,4)]
test_lm<-lm(log(selling_price) ~.,data = car1)
summary(test_lm)
(summary(test_lm)$coefficient)
```

\#applico un plot per analizzare la variabile target sui residui \#(bisogna allargare l'asse x su alcuni plot per vedere meglio l'andamento) \#Nel secondo diagramma per la regressione ideale i punti dovrebbero trovarsi sulla retta diagonale e per questo motivo il nostro risultato non è così male da rifiutare il modello. \#negli altri grafici invece affinchè si ottenga una regressione lineare corretta le linee rosse si sarebbero dovute essere parallele all'asse x (dire se i risultati sono più o meno accettabili dopo aver allargato l'asse delle x per l'osservazione)

```{r faccio un plot per analizzare i grafici che ottengo}
plot(test_lm)

```
