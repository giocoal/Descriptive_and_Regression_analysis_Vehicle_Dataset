---
title: "Probability and statistics project: dataset prezzi auto usate"
author: "Carbone Giorgio, Scuri Gianluca, Gazzola Michele"
date: "09/01/2021"
output: github_document
---

# Importazione librerie

```{r importazione librerie e opzioni di rendering, warning=FALSE, include=FALSE}
library(readr)
library(tibble)
library(dplyr)
library(stringr)
library(caret)
library(ggcorrplot)
library(GGally) #Per il ggcorr()
library(DiscriMiner) # Per il correlation ratio
library(psych)
library(ggrepel)
library(gridExtra)
library(glmnet)
library(xgboost)
library(ggplot2)
library(gridExtra)
library(MASS)
library(mice)
```

# Lettura Dataset

-   Vengono assegnati i fase di lettura i tipi corretti ad ogni variabile
-   Alcune variabili presentano l'unità di misura espressa nel valore, vengono quindi temporaneamente definiti come stringhe

```{r importazione}
data_path <- "https://raw.githubusercontent.com/giocoal/datasets/main/Car%20details%20v3.csv"
car <- read_csv(data_path, col_types = 'ciiiffff????i')
head(data.frame(car))
```

# Obiettivo

L'obiettivo di analisi consiste nella definizione di un modello di regressione lineare multipla che permetta di predire il prezzo di vendita di un'automobile usata, quindi la variabile target sarà `selling_price`.

# Preparazione e pulizia del dataset

#### Scegliamo di non considerare i seguenti attributi

-   Scegliamo di non considerare la colonna mileage perché i consumi delle auto con diverso combustibile non sono comparabili, infatti i combustibili hanno un diverso rapporto energia generata per unità di volume
-   L'attributo torque, in quanto calcolato a rpm diversi per ogni veicolo/marca, lo escludiamo dall'analisi

```{r rimozione colonna torque e mileage}
car <- dplyr::select(car, -c(torque,mileage))
head(car)
```

#### Conversione unità di misura della variabile selling_price

Conversione dell'unità di misura del prezzo di vendita da centesimi di dollaro in dollaro

```{r da centesimo a dollaro}
car$selling_price <- car$selling_price*0.01
```

#### Conversione variabile `year` (anno di produzione) in `age` (anni di vita)

Conversione della variabile `year` (anno di produzione) in `age` (anni di vita dell'auto nell'anno di vendita, ovvero il 2021)

```{r conversione year in age}
car <- add_column(car, age = 2021 - car$year, .after = "year")
car <- dplyr::select(car, -c("year"))
```

#### Introduzione di NA per l'attributo max_power

L'attributo max_power presenta dei missing value in cui però la cella non è vuota ma presenta la sola unità di misura 'bhp'

```{r from 0 to NA}
car$max_power[car$max_power == 0 | car$max_power == "bhp"] <- NA
```

#### Verifico che le unità di misura di ogni singolo attributo siano consistenti tra loro

```{r Controllo unita di misura}
all(grepl("CC", car$engine) == !is.na(car$engine))
all((grepl("bhp", car$max_power)) == !is.na(car$max_power))
```

Entrambi risultano TRUE, questo significa che le unità di misura sono consistenti per tutte le osservazioni dei due attributi.

#### Conversione degli attributi in cui i valori sono stringhe contenenti i valori accompagnati dall'unità di misura in valori numerici privi di unità di misura

-   A tale scopo utilizziamo la funzione `parse_value` di `dplyr`

-   Elimino gli attributi contenenti i valori accoppiati alle unità di misura con la funzione `select()` di `dplyr`

```{r Eliminazione unità di misura}
car['engine_CC'] <- parse_number(car$engine)
car['max_power_bhp'] <- parse_number(car$max_power)
car <- dplyr::select(car, -c('engine', 'max_power'))
```

#### Creazione di una colonna contenente la marca dell'auto

-   Uso la funzione `word` di `dplyr` per estrarre la prima parola del nome dell'auto, la quale coincide con la marca dell'auto.

-   Creo la variabile categoriale `make` che indica la marca dell'auto e la inserisco nel dataset con la funzione `add_column` della libreria `tibble`

```{r colonna marca}
car <- add_column(car, make = factor(word(car$name, 1)), .after = "name")
```

# Statistica descrittiva

## Missing Value

-   Dalla visualizzazione prodotta con l'ausilio della funzione `md.pattern` del pacchetto `mice` notiamo come:

    -   una riga presenta un solo missing value

    -   222 righe presentano tre missing value

-   Essendo le righe contenenti `NA` circa il 3% del delle unità statistiche, decidiamo di rimuoverle

```{r missing value, echo = c(3,6)}
# md.pattern (del pacchetto mice), è una funzione di visualizzazione molto utile
# Permette di vedere la distribuzione di NA nel dataset
md.pattern(car, rotate.names=TRUE)
#numero di righe con almeno un NA (coincide con quanto visto in md.pattern)
# sum(!complete.cases(car))
car <- car[-which(!complete.cases(car)),]
```

## Outliers

Creiamo un subset del dataset contenente le sole variabili quantitative

```{r Estrazione delle variabili numeriche}
car_nums_colnames <- unlist(lapply(car, is.numeric))
car_num <- car[ , car_nums_colnames]
car_num <- dplyr::select(car_num, -c('seats'))
```

Osserviamo i valori minimi e massimi per ogni attributo quantitativo

```{r}
summary(car_num)
```

Valuto la presenza di outliers nelle variabili quantitative (e, quando presenti, delle rispettive variabili con trasformazione logaritmica) tramite l'osservazione dei *boxplot*.

```{r boxplot per outliers}
par(mfrow=c(2,3))
#summary(car_num)
for (i in names(car_num)) {
  boxplot(car_num[[i]], xlab = i, main = '')
}
par(mfrow=c(1,1))
```

Tutte le variabili presentano un numero elevato di sospetti outliers. In particolare, tutte le variabili presentano un certo numero di osservazioni classificate come potenziali valori anomali perchè si trovano al di sopra del baffo superiore del boxplot, la cui posizione è definita come $q\_{0.75} + 1.5 \\cdot IQR$ , dove IQR è il range interquartile. Proviamo a escludere dai potenziali outlier i *mild outlier* e andiamo invece solo a considerare gli *extreme outlier*, aumentando il range di osservazioni incluse nei baffi del boxplot da$I = [q\_{0.25} - 1.5 \\cdot IQR; q\_{0.75} + 1.5 \\cdot IQR]$ a $I = [q\_{0.25} - 3 \\cdot IQR; q\_{0.75} + 3 \\cdot IQR]$

Inoltre, dato che gli outlier sono solo osservazioni che si trovano al di sopra del baffo superiore dei boxplot, proviamo ad applicare una trasformazione logaritmica.

```{r boxplot log}
par(mfrow=c(2,3))
for (i in names(car_num)) {
  boxplot(log10(car_num[[i]]), main = '', xlab = i, range = 3)
}
par(mfrow=c(1,1))

```

Rimuoviamo alcune unità statistiche (lo 0.6% del dataset) contenenti valori anomali particolarmente distanti dalle altre osservazioni disponibili.

```{r}
car_num <- car_num[car_num$selling_price < 80000, ]
car_num <- car_num[car_num$engine_CC < 3000, ]
car_num <- car_num[car_num$max_power_bhp < 300, ]
car_num <- car_num[car_num$km_driven < 300000 & car_num$km_driven > 1, ]

car <- car[car$selling_price < 80000, ]
car <- car[car$engine_CC < 3000, ]
car <- car[car$max_power_bhp < 300, ]
car <- car[car$km_driven < 300000 & car$km_driven > 1, ]
```

## Analisi Distribuzionale variabili quantitative

### Fase esplorativa

```{r lettura}
summary(car)
```

-   Il dataset ha 8123 unità statistiche e 13 attributi

### Variabile Target: selling_price

La variabile target `selling_price` è quantitativa continua

#### Indicatori Statistici

```{r statistical indicators}
summary(car$selling_price)
```

#### Visualizzazioni e analisi della forma della distribuzione

Osserviamo la distribuzione della variabile target `selling_price` utilizzando come visualizzazione un istogramma. Nel grafico viene inserita una stima della funzione di densità di probabilità ottenuta con il metodo *kernel density estimation (KDE).*

```{r istogramma selling price}
car %>% ggplot()+geom_histogram(aes(selling_price, ..density..), bins = 30, )+geom_density(aes(selling_price))+ggtitle('Istogramma di selling_price (prezzo di vendita auto usate)')+xlab('Selling Price')+ylab('Densità')
```

Valutiamo la simmetria della distribuzione con l'ausilio dell'*indice di simmetria di Pearson* e la curtosi con L'*indice di curtosi di Pearson*

```{r}
print(paste("Indice di asimmetria della variabile response selling_price:", skew(car$selling_price), sep = " "))
print(paste("Indice di curtosi della variabile response selling_price:", kurtosi(car$selling_price), sep = " "))
```

La distribuzione presenta una forte asimmetria positiva, con una coda di destra molto lunga, inoltre essa soffre di un *eccesso di curtosi* (essendo il valore dell'indice di curtosi maggiore di 3)

Proviamo a visualizzare nuovamente la variabile dopo l'applicazione di una trasformazione logaritmica.

```{r istogramma selling_price_log}
car %>% ggplot()+geom_histogram(aes(selling_price, ..density..), bins = 30, )+geom_density(aes(selling_price))+ggtitle('Istogramma del logaritmo di selling_price (prezzo di vendita auto usate)')+xlab('Selling Price')+ylab('Densità')+scale_x_log10()
```

Valutiamo la simmetria e la curtosi della distribuzione dopo l'applicazione della trasformazione logaritmica

```{r simmetria e curtosi log_selling_price}
print(paste("Indice di asimmetria della variabile response selling_price:", skew(log10(car$selling_price)), sep = " "))
print(paste("Indice di curtosi della variabile response selling_price:", kurtosi(log10(car$selling_price)), sep = " "))
```

La variabile target, in seguito alla trasformazione logaritmica, risulta più simmetrica e non più affetta da eccesso di curtosi, quindi questa sarà trasformata prima di procedere con la fase di inferenza.

### Analisi distribuzione variabili esplicative quantitative

#### Indicatori statistici

```{r indicatori statistici}
summary(car_num)
```

#### Visualizzazioni e analisi della forma della distribuzioni

In modo analogo a quanto fatto con la variabile target, osserviamo la distribuzione delle variabili esplicative quantitative `year`, `km_driven`, `seats`, `engine_CC` e `max_power_bhp`.

```{r istogrammi}
plot1 <- car_num %>% ggplot()+geom_histogram(aes(age, ..density..), bins=15)+geom_density(aes(age))+ylab('')

plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30)+geom_density(aes(km_driven))+scale_x_continuous(labels = function(x) format(x, scientific = F))+ylab('')

plot3 <- car_num %>% ggplot()+geom_histogram(aes(engine_CC, ..density..), bins=30)+geom_density(aes(engine_CC))+ylab('')

plot4 <- car_num %>% ggplot()+geom_histogram(aes(max_power_bhp, ..density..), bins=25)+geom_density(aes(max_power_bhp))+ylab('')

grid.arrange(plot1, plot2, plot3, plot4, ncol = 2,
             top = "Istogrammi delle distribuzioni delle variabili esplicative quantitative",
             left = "Densità"
             )
```

Calcoliamo l'*indice di asimmetria di Pearson*

```{r indice di asimmetria}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di asimmetria di Pearson di",i,":", skew(car_num[[i]]), sep = " "))
}
```

Calcoliamo l'*indice di curtosi di Pearson,* al fine di quantificare la curtosi ovvero lo 'spessore' delle code delle distribuzioni

```{r indice di curtosi di Pearson}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di curtosi di Pearson di",i,":", kurtosi(car_num[[i]]), sep = " "))
}
```

Traiamo le seguenti conclusioni riguardo la simmetria delle variabili:

-   age: asimmetria positiva
-   km_driven: asimmetria positiva, coda di destra molto pronunciata
-   engine_CC: asimmetria positiva
-   max_power_bhp: asimmetria positiva pronunciata, curtosi pronunciata vicina a una condizione di *eccesso di curtosi*

Valutiamo la forma delle distribuzioni delle variabili esplicative quantitative dopo l'applicazione di una trasformazione logaritmica.

```{r indice di simmetria di Pearson trasformazione logaritmica}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di asimmetria di",i,":", skew(log10(car_num[[i]])), sep = " "))
}
```

```{r indice di curtosi di Pearson trasformazione logaritmica}
for (i in names(car_num)) {
  if (i == 'selling_price'){
    next
  }
  print(paste("Indice di curtosi di Pearson di",i,":", kurtosi(log10(car_num[[i]])), sep = " "))
}
```

```{r istogrammi log}
plot1 <- car_num %>% ggplot()+geom_histogram(aes(age, ..density..), bins=15)+geom_density(aes(age))+ylab('')+scale_x_log10()

plot2 <- car_num %>% ggplot()+geom_histogram(aes(km_driven, ..density..), bins=30)+geom_density(aes(km_driven))+theme(axis.text.x = element_text(angle = 10))+ylab('')+scale_x_log10()

plot3 <- car_num %>% ggplot()+geom_histogram(aes(engine_CC, ..density..), bins=30)+geom_density(aes(engine_CC))+ylab('')+scale_x_log10()

plot4 <- car_num %>% ggplot()+geom_histogram(aes(max_power_bhp, ..density..), bins=30)+geom_density(aes(max_power_bhp))+ylab('')+scale_x_log10()

grid.arrange(plot1, plot2, plot3, plot4, ncol = 2,
             top = "Istogrammi delle distribuzioni delle variabili esplicative quantitative \n dopo l'applicazione della trasformazione logaritmica",
             left = "Densità"
             )
```

Viene applicata la trasformazione logaritmica a `age`, `engine_CC` e `max_power_bhp` perché applicando la forma della trasformazione logaritmica la distribuzione migliora sia dal punto di vista della simmetria che della curtosi

```{r trasformazione logaritmica}
car <- add_column(car, log_selling_price = log10(car$selling_price), .after = "selling_price")
car <- add_column(car, log_age = log10(car$age), .after = "age")
car <- add_column(car, log_max_power_bhp = log10(car$max_power_bhp), .after = "max_power_bhp")
car <- add_column(car, log_engine_CC = log10(car$engine_CC), .after = "engine_CC")

car_num <- add_column(car_num, log_selling_price = log10(car_num$selling_price), .after = "selling_price")
car_num <- add_column(car_num, log_age = log10(car_num$age), .after = "age")
car_num <- add_column(car_num, log_max_power_bhp = log10(car_num$max_power_bhp), .after = "max_power_bhp")
car_num <- add_column(car_num, log_engine_CC = log10(car_num$engine_CC), .after = "engine_CC")
```

## Analisi distribuzionale variabili qualitative

### `fuel`: tipo di carburante

```{r tipo di carburante}
# coef = 3 indica la lunghezza dei baffi come multipli dell'IQR (porto da 1.5 a 4)
car %>% ggplot(aes(fuel, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")
```

Sono presentati i boxplot delle distribuzioni di `selling_price` in funzione del tipo di `fuel`. Per ogni distribuzione, mediante l'utilizzo di linee orizzontati sono rappresentati rispettivamente (partendo dal basso) il primo quartile, la mediana e il terzo quartile. Viene inoltre aggiunta, sfruttando `stat_summary` la media, rappresentata da un punto di colore rosso.

Dalle distribuzioni si evince come:

-   in media e in mediana, il prezzo di vendita di una macchina a GPL usata risulti essere il minore. Invece, per le auto a Diesel, si ha una concentrazione di osservazioni a valori di `selling_price` maggiori e un prezzo medio maggiore rispetto a auto con altre tipologie di carburante.

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlaizone fuel}
corRatio(car$log_selling_price, car$fuel)
```

Il valore ottenuto evidenzia dipendenza in media molto leggera.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrato* tra `log_selling_price` e `fuel`:

```{r indice di connessione fuel}
chisq_price_fuel <- chisq.test(car$log_selling_price, car$fuel, simulate.p.value = TRUE)
chisq_price_fuel$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Tipo di proprietario: `owner`

```{r tipo di proprietario}
car %>% ggplot(aes(owner, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")+theme(axis.text.x = element_text(angle = 20, hjust = 1))
```

Dalle distribuzioni si evince come:

-   in media e in mediana, il prezzo di vendita di un'automobile usata tenda a diminuire all'aumentare del numero di precedenti proprietari dell'auto (sembra quindi ci sia una dipendenza in media tra `log_selling_price` e `owner`.

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlaizone owner}
corRatio(car$log_selling_price, car$owner)
```

Il valore ottenuto evidenzia una leggera dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrato* tra `log_selling_price` e `owner`:

```{r indice di connessione owner}
chisq_price_owner <- chisq.test(car$log_selling_price, car$owner, simulate.p.value = TRUE)
chisq_price_owner$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Distribuzione delle marche di auto (`make`)

Visualizziamo la distribuzione delle marche di auto usate vendute con l'ausilio di un grafico a barre, al fine di avere una visualizzazione più agile escludiamo le marche con frequenza assoluta minore di 90.

```{r make boxplot count}
car %>% group_by(make) %>% count() %>% arrange(desc(n)) %>% ggplot() + geom_col(aes(x=n,y=reorder(make,n)), show.legend = F)+
labs(title = 'Distribuzione marche di auto ordinate per frequenza assoluta',
     subtitle = '',
     x= 'Frequenza Assoluta',
     y='make')
```

Osserviamo invece ora la distribuzione di `selling price` condizionata a `make` attraverso dei boxplot. Nei boxplot viene inoltre rappresentata la dispersione dei valori di `selling_price` con lo scopo principale di evidenziare il numero di auto di una specifica marca presenti nel dataset.

```{r selling_price make}
car %>% ggplot(aes(reorder(make, selling_price, median), selling_price))+geom_boxplot()+geom_jitter(alpha=0.02)+geom_hline(aes(yintercept=median(selling_price)))+coord_flip()+xlab('make (marche ordinate per prezzo mediano)')+ylab('selling_price')+theme(aspect.ratio=1)+scale_y_log10()
```

Dalla visualizzazione possiamo dedurre come le auto usate di marche di lusso non abbiano un mercato particolarmente ampio, mentre le marche di auto non di lusso, con un prezzo mediano inferiore, vengono vendute maggiormente.

### Cambio automatico vs cambio manuale: `transmission`

```{r tipo di cambio}
car %>% ggplot(aes(transmission, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")
```

Dalle distribuzioni si evince come:

-   Il numero di auto usate vendute che presentano cambio manuale sia significativamente maggiore di quelle con cambio automatico
-   In media e in mediana, il prezzo di vendita di un'automobile sembra essere maggiore per le auto dotate di cambio automatico (sembra ci sia una dipendenza in media tra la variabile `selling_price` e `transmission`)

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlazione transmission}
corRatio(car$log_selling_price, car$transmission)
```

Il valore ottenuto evidenzia una moderata dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrati* tra `log_selling_price` e `transmission`:

```{r indice di connessione transmission}
chisq_price_transmission <- chisq.test(car$log_selling_price, car$transmission, simulate.p.value = TRUE)
chisq_price_transmission$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

### Tipo di venditore: `seller_type`

```{r tipo di seller}
car %>% ggplot(aes(seller_type, log_selling_price))+geom_boxplot(coef = 3)+geom_jitter(alpha=0.05)+theme(axis.text.x = element_text(angle = 0, hjust = 1))+stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red", fill="red")
```

Dalle distribuzioni si evince come:

-   Il numero di auto usate vendute da privati è maggiore di quelle vendute da dealer (venditore) e da trustmark dealer (venditore con garanzia).
-   In media e in mediana, il prezzo di vendita di un'automobile sembra essere maggiore per le auto dotate di cambio automatico (sembra esserci una certa dipendenza in media tra `log_selling_price` e `seller_type`)

Al fine di verificare la presenza di indipendenza in media calcoliamo il *rapporto di correlazione*

```{r rapporto di correlazione seller}
corRatio(car$log_selling_price, car$seller_type)
```

Il valore ottenuto evidenzia una leggera dipendenza in media.

Al fine di verificare la presenza di indipendenza in distribuzione calcoliamo *l'indice di connessione chi-quadrati* tra `log_selling_price` e `seller_type`:

```{r indice di connessione seller}
chisq_price_seller_type <- chisq.test(car$log_selling_price, car$seller_type, simulate.p.value = TRUE)
chisq_price_transmission$statistic
```

Il valore dell'indice di connessione, maggiore di zero, suggerisce la presenza di dipendenza in distribuzione.

## Analisi delle correlazioni

Visualizzo possibili correlazioni osservando i *pair plots* (diagrammi a dispersione accoppiati) tra le variabili quantitative.
Al fine di rendere più agile la rappresentazione grafica viene selezionato tramite *simple random sampling* un campione di 500 unità statistiche del dataset originale.

```{r correlazioni}
# Aggiorno il vettore delle colonne numeriche di car
car_nums_colnames_log <- c('log_age','log_selling_price','km_driven','log_engine_CC','log_max_power_bhp', 'seats')
# Prendo un campione di osservazioni per rendere più agile la rappresentazione grafica:
leggero <- car[sample(nrow(car), 500), ]
# Matrice dei diagrammi di dispersione: (non serve usare le variabili trasformate perchè la correlazione non cambia)
pairs(leggero[, car_nums_colnames_log])
cor(car[ ,car_nums_colnames_log])
```

Al fine di evidenziare le correlazioni osservo i *coefficienti di correlazione di Pearson*

```{r Pearson}
ggcorr(car[,car_nums_colnames_log], label = TRUE, label_size = 2.9, hjust = 1, layout.exp = 2)

```

Osservando i *coefficienti di correlazione di Pearson* deduciamo che la variabile target `log_selling_price` presenza:

-   Debole associazione positiva con la variabile `seats`

-   Debole associazione negativa con la variabile `km_driven`

-   Moderata associazione positiva con la variabile `log_engine_CC`

-   **Forte associazione positiva** con la variabile `log_max_power_bhp` (0.7)

-   **Forte associazione negativa** con la variabile `log_age` (-0.7)

Per quanto riguarda le associazioni tra le variabili esplicative, si evidenziano alcuni problemi collegati a una probabile **multicollinarità**:

-   `seats` presenta forte associazione positiva con `log_engine_CC`

    -   successivamente escluderemo `seats` dalla stima del modello di regressione perché tra le due è la meno correlata con `selling_price`

-   `log_max_power_bhp` presenta forte associazione positiva con `log_engine_CC`

    -   successivamente escluderemo `log_engine_CC` dalla stima del modello di regressione perché tra le due è la meno correlata con `selling_price`

-   `km_driven` presenta una moderata associazione con `log_age`

# Statistica inferenziale

## Preparazione

### Analisi righe duplicate

Quantifico il numero di righe duplicate presenti.

```{r quantifico righe duplicare}
sum(duplicated(car))
```

Sono presenti 1183 righe che descrivono auto uguali, dello stesso anno, con gli stessi km e prezzo. La cosa è sospetta ed inoltre queste righe non possono riferirsi alla stessa auto rivenduta più volte altrimenti cambierebbe il campo `owner`. Probabilmente per la maggior parte delle righe è dovuto ad un cattivo inserimento dei dati, per questo decidiamo di rimuoverle.

```{r distribuzione selling_price}
car_noduplicati <- distinct(car)

plot1 <- car %>% ggplot()+geom_histogram(aes(log_selling_price, ..density..), bins = 30, )+geom_density(aes(log_selling_price))+ggtitle('Istogramma con righe duplicate')+xlab('Selling Price (log10)')+ylab('Densità')

plot2 <- car_noduplicati %>% ggplot()+geom_histogram(aes(log_selling_price, ..density..), bins = 30, )+geom_density(aes(log_selling_price))+ggtitle('Istogramma senza righe duplicate')+xlab('Selling Price (log10)')+ylab('Densità')

plot3 <- ggplot(car, aes(sample = log_selling_price)) + stat_qq() + stat_qq_line(col = "red")+ggtitle('Normal Q-Q con righe duplicate')+xlab('Theoretical Quantiles')+ylab('Sample Quantiles')

plot4 <- ggplot(car_noduplicati, aes(sample = log_selling_price)) + stat_qq() + stat_qq_line(col = "red")+ggtitle('Normal Q-Q senza righe duplicate')+xlab('Theoretical Quantiles')+ylab('Sample Quantiles')

grid.arrange(plot1, plot3, plot2, plot4, ncol = 2)
```

Rimuovendo le righe duplicate si vede anche un miglioramento nella distribuzione della variabile `log_selling_price`. Anche il Normal Q-Q Plot è migliorato anche se le code risultano comunque un po' più spesse della distribuzione normale.

### Categorie poco rappresentate

Individuo le marche con un numero di conteggi minore di 13, su cui non potrei fare una corretta statistica inferenziale una volta splittato il dataset in `train_set` e `test_set`.

```{r conteggi per categorie make}
conteggi <- count(car_noduplicati, make, sort = TRUE)
drop<-conteggi[conteggi$n < 13,]
drop
```

Rimuovo le 54 righe riferite a 13 marche poco rappresentate.

```{r rimozione auto con marche poco rappresentate}
car_noduplicati_nodrop <- droplevels(car_noduplicati[!(car_noduplicati$make %in% drop$make),])
str(car_noduplicati_nodrop$make)
```

Individuo gli owner con un numero di conteggi minore di 13, su cui non potrei fare una corretta statistica inferenziale una volta splittato il dataset in `train_set` e `test_set`.

```{r conteggi per categorie owner}
conteggi <- count(car_noduplicati, owner, sort = TRUE)
drop<-conteggi[conteggi$n < 13,]
drop
```

```{r rimozione auto con categorie owner poco rappresentate}
car_noduplicati_nodrop <- droplevels(car_noduplicati_nodrop[!(car_noduplicati_nodrop$owner %in% drop$owner),])
str(car_noduplicati_nodrop$owner)
```

Rimuovo le 5 righe riferite a `Test Drive Car` perché poco rappresentata.

```{r rimozione auto con owner poco rappresentate}
car_noduplicati_nodrop <- droplevels(car_noduplicati_nodrop[!(car_noduplicati_nodrop$owner %in% drop$owner),])
str(car_noduplicati_nodrop$owner)
```

Le altre variabili categoriali presentano tutte una numerosità maggiore di 13 per ogni livello.

### Dataset con variabili dummy

Creo un nuovo dataset chiamato `car_dummy` al quale aggiungo le variabili quantitative in forma logaritmica dove necessario. Al dataset appena creato aggiungo le colonne relative alle variabili categoriche in formato dummy. Per ogni attributo vengono generate n-1 nuove colonne dove n è il numero di modalità di quel particolare attributo.

```{r da variabili fattoriali a variabili dummy}

#subset delle variabili quantitative
car_dummy <- car_noduplicati_nodrop[,car_nums_colnames_log]

# Aggiungo la variabile fattoriale 'transmission' a car dummy e la converto in numerica (0 corrispode a 'automatic'):
car_dummy <- cbind(car_dummy,transmission = car_noduplicati_nodrop$transmission)
levels(car_dummy$transmission)<-c(1,0)
car_dummy$transmission <- as.numeric(levels(car_dummy$transmission))[car_dummy$transmission]

#converto la variabile fattoriale 'make' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~make, data = car_noduplicati_nodrop))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'fuel' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~fuel, data = car_noduplicati_nodrop))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'seller_type' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~seller_type, data = car_noduplicati_nodrop))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)

#converto la variabile fattoriale 'owner' in dummy e la aggiungo a car_dummy:
dummy_temp <- data.frame(model.matrix( ~owner, data = car_noduplicati_nodrop))[,-1]
car_dummy <-cbind(car_dummy,dummy_temp)
```

Con tutti i valori a zero per una classe di attributi si ottiene: `Audi` per la classe `make`, `First Owner` per la classe `owner`, `Automatic` per la classe `transmission`, `Diesel` per la classe `fuel`, `Individual` per la classe `seller_type`.

### Training e Test sets

Divido il nuovo dataset creato al punto precedente in due con rapporto 80 20 così da poter allenare il modello sulla partizione più grande (`train_set`) e poterlo poi verificare su quello più piccolo (`test_set`).

```{r split dataset in Train e Test sets}
set.seed(100)
train_ind<-sample(1:nrow(car_dummy),0.8*nrow(car_dummy))

train_set <- car_dummy[train_ind,]
test_set <- car_dummy[-train_ind,]
```

Verifico le dimensioni dei due nuovi dataset.

```{r dimensioni train_set e test_set}
print(paste("Numero righe train_set:", nrow(train_set), sep = " "))
print(paste("Numero righe test_set: ", nrow(test_set), sep = " "))
```

## Regressione lineare

Per poter eseguire la regressione lineare abbiamo diverse assunzioni da fare che andremo in seguito a verificare:

-   **Linearità** tra la variabile target e i regressori;

-   **Omoschedasticità**: la varianza dei residui sia omogenea;

-   **Indipendenza** tra le diverse osservazioni;

-   **Normalità** della distribuzione dei residui;

-   Bassa **multicollinearità.**

### Modello con tutti gli attributi

Iniziamo realizzando un modello di regressione sul `train_set` in cui considero tutte le variabili.

```{r modello completo}
modello_completo <- lm(log_selling_price ~ ., data=train_set)
summary(modello_completo)
```

Ciò che risulta è un modello con un valore dell'R quadro aggiustato elevato `Adjusted R-squared: 0.8587`. Il problema di questo modello però è che diversi attributi sono poco significativi quindi probabilmente il valore R alto è dovuto ad un fenomeno di overfitting. Inoltre alcuni degli attributi presenti sono correlati tra loro e dovremo quindi procedere a rimuoverli.

Dalla tabella dei coefficienti si può osservare anche che gli attributi dummy che presentano la significatività maggiore sono quelli corrispondenti alle modalità più diverse dalla "modalità zero", quella che si ottiene con tutte le colonne di una certa classe uguali a zero (es. BMW e Mercedes sono le auto più simili alla marca Audi).

### Feature selection

Cerchiamo ora di ridurre il numero di attributi necessari per aumentare l'interpretabilità e tentare di ridurre i problemi presenti. Per prima cosa andiamo a rimuovere dal dataset gli attributi che presentano problemi di multicollinearitá, facciamo riferimento alla tabella delle correlazioni della sezione "Analisi delle correlazioni". Dalla tabella si può vedere che l'attributo `log_engine_CC` è molto correlato con `log_max_power_bhp` e decidiamo dunque di rimuoverlo.

```{r rimuovo colonne seats e log_engine_CC}
train_set <- dplyr::select(train_set, -c('log_engine_CC'))
test_set <- dplyr::select(test_set, -c('log_engine_CC'))
```

Dalla tabella delle correlazioni si può inoltre notare come `log_max_power_bhp` e `log_age` siano i due attributi più correlati con `log_selling_price` rispettivamente con valore di `0.74` e `0.67`. Scegliamo quindi `log_max_power_bhp` come primo attributo con cui costruire il nuovo modello.

```{r primo modello con solo log_max_power_bhp}
modello_minimo <- lm(log_selling_price ~ log_max_power_bhp, data=train_set)
summary(modello_minimo)
```

Come ci aspettavamo l'attributo `log_max_power_bhp` è molto significativo per la descrizione del modello con un p-value molto basso e un R quadro comunque abbastanza elevato `Adjusted R-squared:  0.445`. Vediamo ora qui di seguito la rappresentazione grafica della retta trovata.

```{r grafico modello semplificato}
ggplot(train_set, aes(x = log_max_power_bhp, y = log_selling_price)) + geom_point() + stat_smooth(formula = y ~ x, method = "lm", col = "red")
```

Cerchiamo ora di raffinare il modello andando ad includere un numero maggiore di attributi. Per farlo eseguiamo un processo di forward selection. Dato il grande numero di attributi presenti sfruttiamo la funzione stepAIC.

In prima battuta utilizziamo il `modello_minimo` appena realizzato, settiamo `direction = "both"` e indichiamo come scope il `modello_completo`.

```{r modello stepAIC, include=FALSE, results='hide'}
modello_completo <- lm(log_selling_price ~ ., data=train_set) #ricalcolo il modello perché ho rimosso la colonna log_engine_CC
modello_stepAIC <- stepAIC(modello_minimo, direction = "both", scope = formula(modello_completo))
```

```{r risultati modello stepAIC}
summary(modello_stepAIC)
```

Il processo di stepAIC ha portato all'esclusione di 2 attributi: `makeBMW` e `seller_typeTrustmark.Dealer`. Questo ha portato il valore dell'R quadro aggiustato a `Adjusted R-squared:  0.8577`, cioè praticamente identico a quello iniziale. Togliendo quelle colonne abbiamo quindi alleggerito il modello senza perdere di performance.

Per ridurre ulteriormente il numero di attributi da cui è composto il modello è possibile procedere in due modi:

-   selezionare una diversa "modalità nulla" che abbia un maggior numero di attributi simili (es. una marca che faccia auto in una fascia di prezzo inferiore rispetto ad Audi)

-   ricorrere nuovamente ad utilizzare la funzione stepAIC settando il parametro k, che limita la significatività dei parametri, ad un valore corrispondente a `0.001`.

Ricorriamo a questa seconda opzione utilizzando la funzione `qchisq` per calcolare il parametro k.

```{r modello stepAIC con parametro k, include=FALSE}
k_value <- qchisq(0.001, 1, lower.tail = F)
modello_stepAIC_k <- stepAIC(modello_minimo, direction = "both", scope = formula(modello_completo), k = k_value)
```

```{r risultato modello stepAIC con parametro k}
summary(modello_stepAIC_k)
```

Risultano quindi esclusi dal modello 8 degli attributi iniziali, il modello è ora composto da 23 attributi molto significativi. Il valore dell'R quadro aggiustato è `Adjusted R-squared: 0.8557`, cioè praticamente identico a quello individuato in precedenza.

### Confronto modelli trovati

Utilizzando ora la funzione `anova` confrontiamo il modello ottenuto con la funzione stepAIC e quello ottenuto dal processo di stepAIC con parametro k per vedere se la rimozione degli attributi meno significativi è giustificata.

```{r confronto modello_stepAIC con modello_stepAIC_k}
anova(modello_stepAIC_k, modello_stepAIC)
```

La differenza tra il modello ottenuto dalla funzione stepAIC con e senza il valore k è di 6 gradi di libertà. Andando però a valutare il p-value complessivo di questi attributi il loro contributo sembra essere molto significativo. Infatti il valore è di molto inferiore a 0,05 e ci porta ad affermare che il modello più complesso è significativamente migliore del modello più semplice, cioè fornisce un adattamento migliore ai dati.

La funzione anova restituisce inoltre il valore di F che corrisponde al rapporto delle varianze dei due modelli. Le varianze sono una misura della dispersione delle osservazioni dalla media. La statistica F è un rapporto di due quantità che dovrebbero essere approssimativamente uguali nell'ipotesi nulla, che produce una statistica F di circa 1. Nel nostro caso abbiamo una f-test di 13,8 che ci indica una miglior varianza del modello con più attributi.

### Analisi residui

In questa sezione andiamo a studiare i residui del `modello_stepAIC` generando i diagnostic plots.

```{r plot modello stepAIC, warning=FALSE}

plot1 <- qplot(.fitted, .resid, data = modello_stepAIC) + geom_hline(yintercept = 0) + geom_smooth(se = FALSE, col = "red") +ggtitle('Residuals vs Fitted')+ylab('Residuals')+xlab('Fitted values')

plot2 <- qplot(sample =.stdresid, data = modello_stepAIC, stat = "qq") + geom_abline(col = "red")+ggtitle('Normal Q-Q Plot')+ylab('Standardized Residuals')+xlab('Theoretical Quantiles') + geom_text(aes(label = '5491'), x=-3, y=-6.3)

plot3 <- qplot(.fitted, sqrt(abs(.stdresid)), data = modello_stepAIC) + geom_hline(yintercept = 1) + geom_smooth(se = FALSE,col = "red") +ggtitle('Scale - Location')+xlab('Fitted values')+ylab(expression(sqrt(abs('Standardized residuals '))))

plot4 <- qplot(.hat, .stdresid, data = modello_stepAIC) + geom_smooth(se = FALSE,col = "red")+ggtitle('Residuals vs Leverage')+xlab('Leverage')+ylab('Standardized residuals') + geom_hline(yintercept = 0)

grid.arrange(plot1,plot2,plot3,plot4)
```

Analizziamo separatamente i 4 diversi grafici:

-   Il primo mostra eventuali pattern non lineari nei residui che potrebbero suggerire una relazione non lineare tra target e regressori. Nel nostro caso risulta come ci si aspettava una retta orizzontale.

-   Il secondo verifica se la distribuzione dei residui è Gaussiana. Nel nostro caso per valori dei quantili teorici tra -2 e -4 c'è un allontanamento dei dati dalla retta, questo mostra un'asimmetria della distribuzione che affronteremo qui di seguito.

-   Il terzo verifica l'assunzione dell'omoschedasticità. Nel nostro caso si ottiene con buona approssimazione una retta orizzontale che verifica l'assunzione.

-   Il quarto permette di trovare eventuali outliers rimasti che potrebbero modificare in modo significativo il modello. Dei nostri punti nessuno si trova oltre la Cook's distance.

L'anomalia del Normal Q-Q plot indica una asimmetria della distribuzione. Questo è probabilmente dovuto alla mancanza di una variabile nel calcolo del costo di un'auto. Infatti, nonostante il modello descriva bene i dati, potrebbe essere molto migliore se ci fosse una variabile riferita allo stato dell'auto; questo infatti è uno dei parametri che maggiormente può influenzare il costo di un'auto usata. In particolare presumiamo vengono sovrastimati i prezzi dei veicoli che presentano buone caratteristiche sulla carta ma che presentano dei danni.

```{r verifico outlier}
car_noduplicati_nodrop[row.names(car_noduplicati_nodrop) == 5491,]
```

Analizziamo ad esempio l'osservazione 5491 nel qq Plot che è quella che si discosta maggiormente, corrisponde ad una Volkswagen Polo 1.5 TDI Comfortline venduta a 2600$. Confrontandola con le altre righe nel database che corrispondono a questo modello di auto vediamo che hanno tutte prezzi maggiori nonostante siano più vecchie e con più km, questa cosa ci fa pensare quindi che si tratti di un'auto incidentata o seriamente danneggiata.

```{r veirifico il costo delle altre Volkswagen Polo 1.5 TDI Comfortline}
car_noduplicati_nodrop[car_noduplicati_nodrop$name == 'Volkswagen Polo 1.5 TDI Comfortline',]
```

# Analisi predittiva

In questa sezione andiamo ad analizzare le capacità predittive del nostro modello applicandolo al `test_set`. In primo luogo andiamo a controllare il valore dell'R quadro che ci restituisce.

```{r predizione sul test set}
lm_pred <- predict(modello_stepAIC, newdata = test_set %>% dplyr::select(-log_selling_price))
R2(lm_pred, test_set$log_selling_price)
```

Il valore di R quadro che si ottiene è praticamente identico a quello ottenuto sul `train_set` che era di `0.8577`, ciò significa che il modello è buono e predice bene i risultati.

Valutiamo ora anche il Root Mean Squared Error, cioè la misura di errore assoluta con le deviazioni elevate al quadrato. Più basso è il valore dell'RMSE e migliore è il modello rappresentato.

```{r valutazione RMSE}
RMSE(pred = modello_stepAIC$fitted.values, obs = train_set$log_selling_price)  # RMSE of train dataset
RMSE(pred = lm_pred, obs = test_set$log_selling_price)                         # RMSE of test dataset
```

Nel nostro caso i valori dell'RMSE calcolati per entrambi i modelli, sia sul `train_test` che sul `test_set`, sono bassi e risultano praticamente identici per cui possiamo affermare che il modello è buono e nonostante l'alto numero di attributi non ha overfittato il `train_set`.
